{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: This notebook is not optimized for memory nor performance yet. Please use it with caution when handling large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for BDSE12_03G_HomeCredit_V1.csv processing for bear LGBM final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare work environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for managing datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math for operating numbers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change pd displayg format for float\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an easy way to completely show a dataframe in a cell\n",
    "def completeShow(dfToShow, rowLimit:int = 1000, colLimit:int = 1000):\n",
    "    '''\n",
    "    An easy way to completely show a dataframe in a cell.\n",
    "    dfToShow: dataframe you'd like to completely show\n",
    "    rowLimit: upper limit of the row number, could be None or any integer (default: 1000)\n",
    "    colLimit: upper limit of the column number, could be None or any integer  (default: 1000)\n",
    "    '''\n",
    "    with pd.option_context('display.max_rows', rowLimit, 'display.max_columns', colLimit):\n",
    "        print(dfToShow)\n",
    "    \n",
    "# to show complete output of a cell: eg.\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(df.apply(lambda x:x.unique().size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "#Seaborn set() to set aesthetic parameters in one step.\n",
    "sns.set() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for memory management\n",
    "# !pip install psutil\n",
    "# https://psutil.readthedocs.io/en/latest/\n",
    "\n",
    "# import os, psutil, gc\n",
    "# def usage():\n",
    "#     process = psutil.Process(os.getpid())\n",
    "#     return process.memory_info()[0] / float(2 ** 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToRead: multi-threading\n",
    "# http://violin-tao.blogspot.com/2017/05/python3_26.html\n",
    "# https://medium.com/@peilee_98185/%E6%94%BE%E9%96%8B%E9%82%A3%E8%A8%98%E6%86%B6%E9%AB%94-%E4%B9%8B-python-%E8%99%95%E7%90%86%E5%A4%A7%E8%B3%87%E6%96%99-84fd41806694\n",
    "# import multiprocessing as mp\n",
    "# pool = mp.Pool(6) # 裡面填要開幾核心\n",
    "# result = pool.map( data_process_function, dfs )\n",
    "# # dfs 為裝了很多 Pandas DataFrame 的 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "# appl_train_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_eda/application_train.csv')\n",
    "# appl_test_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_eda/application_test.csv')\n",
    "\n",
    "appl_all_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_fteng/BDSE12_03G_HomeCredit_V1.csv',index_col=0)\n",
    "# appl_all_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_fteng/BDSE12_03G_HomeCredit_V1.csv').drop(['unnamed 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appl_train_df.shape, appl_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine application_train and application_test\n",
    "# appl_all_df = pd.concat([appl_train_df, appl_test_df], sort=False, ignore_index=True)\n",
    "# appl_all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df.apply(lambda x:x.unique().size).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df['TARGET'].unique(), \\\n",
    "appl_all_df['TARGET'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df['TARGET'].isnull().sum(), \\\n",
    "appl_all_df['TARGET'].size, \\\n",
    "(appl_all_df['TARGET'].isnull().sum()/appl_all_df['TARGET'].size).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we can use the nullness of 'TARGET' column to separate train & test\n",
    "# assert appl_all_df['TARGET'].isnull().sum() == appl_test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration from other tables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized sampleing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the dataset is too large, I would proceed the following randomized sampling from original dataset to facilitate development and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized sampling from original dataset.\n",
    "# This is just for simplifying the development process\n",
    "# After coding is complete, should replace all df-->df, and remove this cell\n",
    "# Reference: https://yiidtw.github.io/blog/2018-05-29-how-to-shuffle-dataframe-in-pandas/\n",
    "\n",
    "# df= appl_all_df.sample(n = 1000).reset_index(drop=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool: Get numerical/ categorical variables(columns) from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of numerical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with > 3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    num_mask = data_df.apply(lambda x:x.unique().size > unique_value_threshold,axis=0) \n",
    "    num_df = data_df[data_df.columns[num_mask]]\n",
    "    return num_df\n",
    "\n",
    "def get_cat_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of categorical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with =<3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    cat_mask = data_df.apply(lambda x:x.unique().size <= unique_value_threshold,axis=0) \n",
    "    cat_df = data_df[data_df.columns[cat_mask]]\n",
    "    return cat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when doing this assertion with large datasets\n",
    "# assert get_cat_df(appl_all_df, 3).columns.size + get_num_df(appl_all_df, 3).columns.size == appl_all_df.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting id_target_df, cat_df, num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate id and target columns before any further processing\n",
    "id_target_df = appl_all_df.loc[:, ['SK_ID_CURR','TARGET']]\n",
    "\n",
    "# Get the operating appl_all_df by removing id and target columns\n",
    "appl_all_df_opr = appl_all_df.drop(['SK_ID_CURR','TARGET'], axis=1)\n",
    "\n",
    "# A quick check of their shapes\n",
    "appl_all_df.shape, id_target_df.shape, appl_all_df_opr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the numerical and categorical variable containing columns via the tools decribed above.\n",
    "cat_df = get_cat_df (appl_all_df_opr, 100)\n",
    "num_df = get_num_df (appl_all_df_opr, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.info()\n",
    "num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick check of their shapes\n",
    "appl_all_df_opr.shape, cat_df.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cat_df.shape[1] + num_df.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df_opr.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df.shape[1]\n",
    "\n",
    "assert cat_df.shape[0] == num_df.shape[0] == id_target_df.shape[0] \\\n",
    "    == appl_all_df_opr.shape[0] \\\n",
    "    == appl_all_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "appl_all_df_opr.info()\n",
    "appl_all_df.info()\n",
    "del appl_all_df_opr\n",
    "del appl_all_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to String (i.e., python object) and fill nan with String 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj = cat_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(cat_df_obj.dtypes) == object\n",
    "\n",
    "# There are no NA left\n",
    "assert all(cat_df_obj.isnull().sum())==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The float nan will be tranformed to String 'nan'\n",
    "# Use this assertion carefully when dealing with extra-large datasets\n",
    "assert cat_df.isnull().equals(cat_df_obj.isin({'nan'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with special columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'nan' with 'not specified' in column 'FONDKAPREMONT_MODE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the replacement and re-assign the modified column back to the original dataframe\n",
    "cat_df_obj['FONDKAPREMONT_MODE'] = cat_df_obj['FONDKAPREMONT_MODE'].replace('nan','not specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the unique value, it should be 1 less than the original cat_df\n",
    "assert cat_df['FONDKAPREMONT_MODE'].unique().size == cat_df_obj['FONDKAPREMONT_MODE'].unique().size +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "cat_df.info()\n",
    "del cat_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the input dataframe (i.e., cat_df_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj.apply(lambda x:x.unique().size).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies() method deals only with categorical variables.\n",
    "# Although it has a built-in argument 'dummy_na' to manage the na value, \n",
    "# our na value has already been converted to string object which are not recognized by the method.\n",
    "# Let's just move forward as planned\n",
    "cat_df_obj_ohe = pd.get_dummies(cat_df_obj, drop_first=True)\n",
    "cat_df_obj_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the ohe is successful\n",
    "assert np.all(np.isin(cat_df_obj_ohe.values,[0,1])) == True\n",
    "# cat_df_obj_ohe.dtypes\n",
    "assert np.all(cat_df_obj_ohe.dtypes) == 'uint8'\n",
    "# make sure the column counts are correct\n",
    "assert cat_df_obj.apply(lambda x:x.unique().size).sum() == cat_df_obj_ohe.shape[1] + cat_df_obj.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "cat_df_obj.info()\n",
    "del cat_df_obj\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit np.isin(cat_df_obj_ohe.values,[0,1])\n",
    "# # 1.86 s ± 133 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit cat_df_obj_ohe.isin([0 , 1])\n",
    "# # 3.38 s ± 32.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit np.all(np.isin(cat_df_obj_ohe.values,[0,1]))\n",
    "# # 1.85 s ± 28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit np.all(cat_df_obj_ohe.isin([0 , 1]))\n",
    "# # 3.47 s ± 193 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with numerial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get na flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many columns contain na value.\n",
    "num_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df = num_df[num_df.columns[num_df.isna().any()]]\n",
    "num_notna_df = num_df[num_df.columns[num_df.notna().all()]]\n",
    "\n",
    "assert num_isna_df.shape[1] + num_notna_df.shape[1] == num_df.shape[1]\n",
    "assert num_isna_df.shape[0] == num_notna_df.shape[0] == num_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df.shape, num_notna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df.isna().any(): column names for those na containing columns\n",
    "# use it to transform values bool to int, and then add suffix on the column names to get the na-flag df\n",
    "num_naFlag_df = num_isna_df.isna().astype(np.uint8).add_suffix('_na')\n",
    "num_naFlag_df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace na with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df = num_isna_df.fillna(0)\n",
    "num_isna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many columns contain na value.\n",
    "num_isna_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_isna_df.shape == num_naFlag_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.concat([num_notna_df,num_isna_df,num_naFlag_df], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_notna_df.shape[1] + num_isna_df.shape[1] + num_naFlag_df.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del num_notna_df\n",
    "del num_isna_df\n",
    "del num_naFlag_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# might not be very useful at this point\n",
    "def summary_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    summary_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# summary_df(num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### re-casting to reduce memory use (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isfinite(num_df).all().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite = num_df[num_df.columns[np.isfinite(num_df).all()]]\n",
    "# num_df_infinite = num_df[num_df.columns[np.isfinite(num_df).all() == False]]\n",
    "# num_df_finite.shape, num_df_infinite.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert num_df_finite.shape[0] == num_df_infinite.shape[0] == num_df.shape[0]\n",
    "# assert num_df_finite.shape[1] + num_df_infinite.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_mem_usage(props, finite:bool = True):\n",
    "#     props.info(verbose=False)\n",
    "#     start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "#     print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "#     if finite == True:  \n",
    "#         props[props.columns[(props.min()>=0) & (props.max()<255)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) & (props.max()<255)]].astype(np.uint8, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 255) & (props.max()<65535)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 255) & (props.max()<65535)]] \\\n",
    "#         .astype(np.uint16, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 65535) & (props.max()<4294967295)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 65535) & (props.max()<4294967295)]] \\\n",
    "#         .astype(np.uint32, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 4294967295)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 4294967295)]] \\\n",
    "#         .astype(np.uint64, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "#     else:\n",
    "#         props = props.astype(np.float32, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "        \n",
    "#     print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "#     mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "#     print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "#     print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    \n",
    "#     return props\n",
    "\n",
    "# if num_na_df_finite.min()>=0:\n",
    "#     if num_na_df_finite.max() < 255:\n",
    "#         props[col] = props[col].astype(np.uint8)\n",
    "#     elif num_na_df_finite.max() < 65535:\n",
    "#         props[col] = props[col].astype(np.uint16)\n",
    "#     elif num_na_df_finite.max() < 4294967295:\n",
    "#         props[col] = props[col].astype(np.uint32)\n",
    "#     else:\n",
    "#         props[col] = props[col].astype(np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite = reduce_mem_usage(num_df_finite, finite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_infinite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_infinite = reduce_mem_usage(num_df_infinite, finite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df = pd.concat([num_df_finite, num_df_infinite], axis ='columns')\n",
    "# num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert num_df_finite.shape[0] == num_df_infinite.shape[0] == num_df.shape[0]\n",
    "# assert num_df_finite.shape[1] + num_df_infinite.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del num_df_finite\n",
    "# del num_df_infinite\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization (DO LATER!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generally, in tree-based models, the scale of the features does not matter.\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#normalization\n",
    "https://datascience.stackexchange.com/questions/22036/how-does-lightgbm-deal-with-value-scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine to a complete, processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.array([id_target_df, cat_df_obj_ohe, num_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_target_df.shape, cat_df_obj_ohe.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df = pd.concat(frames, axis ='columns')\n",
    "appl_all_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert appl_all_processed_df.shape[1] == id_target_df.shape[1] + cat_df_obj_ohe.shape[1] + num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del id_target_df\n",
    "del cat_df_obj_ohe\n",
    "del num_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below not executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the 'TARGET' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanceFactor = ((appl_all_processed_df['TARGET'].value_counts()[0])/(appl_all_processed_df['TARGET'].value_counts()[1])).round(0).astype(int)\n",
    "balanceFactor\n",
    "# appl_all_processed_df['TARGET'].value_counts()[0]\n",
    "# appl_all_processed_df['TARGET'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df = appl_all_processed_df[appl_all_processed_df['TARGET']==1]\n",
    "default_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df_balanced = pd.concat( [default_df] * (balanceFactor - 1), sort=False, ignore_index=True )\n",
    "default_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df_balanced = pd.concat([appl_all_processed_df , default_df_balanced], sort=False, ignore_index=True)\n",
    "appl_all_processed_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(appl_all_processed_df_balanced['TARGET'].unique(),\n",
    "(appl_all_processed_df_balanced['TARGET'].value_counts()[1], \\\n",
    "appl_all_processed_df_balanced['TARGET'].value_counts()[0], \\\n",
    "appl_all_processed_df_balanced['TARGET'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del appl_all_processed_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df_balanced.to_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_fromBDSE12_03G_HomeCredit_V1_20200201b_balanced.csv', index = False)\n",
    "# appl_all_processed_df_balanced.to_csv('../../../BDSE12-Group3/datasets/homecdt_fteng/ss_output/ss_fteng_appl_all_v1_20200128.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del appl_all_processed_df_balanced\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "* cleaning:\n",
    "    * num_df: normalize with z-score\n",
    "* feature engineering:\n",
    "    * make reciprocol, polynomial columns of the existing columns. 1/x, x^x.\n",
    "    * multiplying each columns, two columns at a time.\n",
    "    * asset items, income items, willingness(history + misc profile) items, loading(principle + interest) items\n",
    "    * Integration from other tables?\n",
    "\n",
    "https://ithelp.ithome.com.tw/articles/10202059\n",
    "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "https://www.kaggle.com/parasjindal96/how-to-normalize-dataframe-pandas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcol = df['CNT_FAM_MEMBERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numcol.describe(), \\\n",
    "numcol.isnull().sum(), \\\n",
    "numcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcol.value_counts(sort=True), numcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numcol_toYear = pd.to_numeric(\\\n",
    "#                               ((numcol.abs() / 365) \\\n",
    "#                                .round(0)) \\\n",
    "#                               ,downcast='integer')\n",
    "# numcol_toYear.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# numcol_toYear.value_counts(sort=True), numcol_toYear.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol = df['HOUR_APPR_PROCESS_START']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.unique(), \\\n",
    "catcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool: Getting summary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might not be very useful at this point\n",
    "def summary_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    summary_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return summary_df\n",
    "\n",
    "def data_quality_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    data_quality_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return data_quality_df.iloc[[11,13,12,0,],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_quality_df(appl_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# data_quality_df(df).to_csv(\"./eda_output/application_train_data_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# summary_df(df).to_csv(\"./eda_output/application_train_summary_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .nunique() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique() function excludes NaN \n",
    "# i.e. it does not consider NaN as a \"value\", therefore NaN is not counted as a \"unique value\"\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() == df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .value_counts() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .value_counts() function has similar viewpoint towards NaN.\n",
    "# i.e. it does not consider null as a value, therefore not counted in .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['NAME_TYPE_SUITE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].value_counts().sum() + df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum() == \\\n",
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重複值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting unique values (cf. .nunique() function, see above section)\n",
    "# This code was retrieved from HT\n",
    "\n",
    "df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the same if you write (df.apply(lambda x:x.unique().size))\n",
    "assert (df.apply(lambda x:x.unique().shape[0])==df.apply(lambda x:x.unique().size)).all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %timeit showed the performances are similar\n",
    "# %timeit df.apply(lambda x:x.unique().shape[0])\n",
    "# %timeit df.apply(lambda x:x.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 含空值欄位占比\n",
    "print(f\"{df.isnull().any().sum()} in {df.shape[1]} columns (ratio: {(df.isnull().any().sum()/df.shape[1]).round(2)}) has empty value(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
