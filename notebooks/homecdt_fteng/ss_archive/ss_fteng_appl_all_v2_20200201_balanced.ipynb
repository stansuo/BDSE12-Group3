{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: This notebook is not optimized for memory nor performance yet. Please use it with caution when handling large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using application train+test as the first target, then consider aggregation (grouping) issue across the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare work environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for managing datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.17.4', '0.25.3')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math for operating numbers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change pd displayg format for float\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an easy way to completely show a dataframe in a cell\n",
    "def completeShow(dfToShow, rowLimit:int = 1000, colLimit:int = 1000):\n",
    "    '''\n",
    "    An easy way to completely show a dataframe in a cell.\n",
    "    dfToShow: dataframe you'd like to completely show\n",
    "    rowLimit: upper limit of the row number, could be None or any integer (default: 1000)\n",
    "    colLimit: upper limit of the column number, could be None or any integer  (default: 1000)\n",
    "    '''\n",
    "    with pd.option_context('display.max_rows', rowLimit, 'display.max_columns', colLimit):\n",
    "        print(dfToShow)\n",
    "    \n",
    "# to show complete output of a cell: eg.\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(df.apply(lambda x:x.unique().size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "#Seaborn set() to set aesthetic parameters in one step.\n",
    "sns.set() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for memory management\n",
    "# !pip install psutil\n",
    "# https://psutil.readthedocs.io/en/latest/\n",
    "\n",
    "# import os, psutil, gc\n",
    "# def usage():\n",
    "#     process = psutil.Process(os.getpid())\n",
    "#     return process.memory_info()[0] / float(2 ** 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToRead: multi-threading\n",
    "# http://violin-tao.blogspot.com/2017/05/python3_26.html\n",
    "# https://medium.com/@peilee_98185/%E6%94%BE%E9%96%8B%E9%82%A3%E8%A8%98%E6%86%B6%E9%AB%94-%E4%B9%8B-python-%E8%99%95%E7%90%86%E5%A4%A7%E8%B3%87%E6%96%99-84fd41806694\n",
    "# import multiprocessing as mp\n",
    "# pool = mp.Pool(6) # 裡面填要開幾核心\n",
    "# result = pool.map( data_process_function, dfs )\n",
    "# # dfs 為裝了很多 Pandas DataFrame 的 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "appl_train_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_eda/application_train.csv')\n",
    "appl_test_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_eda/application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 121)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine application_train and application_test\n",
    "appl_all_df = pd.concat([appl_train_df, appl_test_df], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 122)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       122.0000\n",
       "mean      6,356.8279\n",
       "std      36,078.9863\n",
       "min           2.0000\n",
       "25%           2.0000\n",
       "50%          26.0000\n",
       "75%       1,153.0000\n",
       "max     356,255.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df.apply(lambda x:x.unique().size).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0., nan]), 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df['TARGET'].unique(), \\\n",
    "appl_all_df['TARGET'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000    282686\n",
       "1.0000     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 356255, 0.1368)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df['TARGET'].isnull().sum(), \\\n",
    "appl_all_df['TARGET'].size, \\\n",
    "(appl_all_df['TARGET'].isnull().sum()/appl_all_df['TARGET'].size).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we can use the nullness of 'TARGET' column to separate train & test\n",
    "assert appl_all_df['TARGET'].isnull().sum() == appl_test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration from other tables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized sampleing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the dataset is too large, I would proceed the following randomized sampling from original dataset to facilitate development and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized sampling from original dataset.\n",
    "# This is just for simplifying the development process\n",
    "# After coding is complete, should replace all df-->df, and remove this cell\n",
    "# Reference: https://yiidtw.github.io/blog/2018-05-29-how-to-shuffle-dataframe-in-pandas/\n",
    "\n",
    "# df= appl_all_df.sample(n = 1000).reset_index(drop=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool: Get numerical/ categorical variables(columns) from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of numerical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with > 3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    num_mask = data_df.apply(lambda x:x.unique().size > unique_value_threshold,axis=0) \n",
    "    num_df = data_df[data_df.columns[num_mask]]\n",
    "    return num_df\n",
    "\n",
    "def get_cat_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of categorical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with =<3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    cat_mask = data_df.apply(lambda x:x.unique().size <= unique_value_threshold,axis=0) \n",
    "    cat_df = data_df[data_df.columns[cat_mask]]\n",
    "    return cat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when doing this assertion with large datasets\n",
    "# assert get_cat_df(appl_all_df, 3).columns.size + get_num_df(appl_all_df, 3).columns.size == appl_all_df.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting id_target_df, cat_df, num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356255, 122), (356255, 2), (356255, 120))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate id and target columns before any further processing\n",
    "# id_target_df = appl_all_df.iloc[:,:2]\n",
    "id_target_df = appl_all_df.loc[:, ['SK_ID_CURR','TARGET']] # modified 2020/01/31\n",
    "\n",
    "# Get the operating appl_all_df by removing id and target columns\n",
    "# appl_all_df_opr = appl_all_df.iloc[:,2:]\n",
    "appl_all_df_opr = appl_all_df.drop(['SK_ID_CURR','TARGET'], axis=1) # modified 2020/01/31\n",
    "\n",
    "# A quick check of their shapes\n",
    "appl_all_df.shape, id_target_df.shape, appl_all_df_opr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the numerical and categorical variable containing columns via the tools decribed above.\n",
    "cat_df = get_cat_df (appl_all_df_opr, 100)\n",
    "num_df = get_num_df (appl_all_df_opr, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356255, 120), (356255, 73), (356255, 47))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick check of their shapes\n",
    "appl_all_df_opr.shape, cat_df.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cat_df.shape[1] + num_df.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df_opr.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df.shape[1]\n",
    "\n",
    "assert cat_df.shape[0] == num_df.shape[0] == id_target_df.shape[0] \\\n",
    "    == appl_all_df_opr.shape[0] \\\n",
    "    == appl_all_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the following gc if memory is running slow\n",
    "# appl_all_df_opr.info()\n",
    "# del appl_all_df_opr\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to String (i.e., python object) and fill nan with String 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj = cat_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(cat_df_obj.dtypes) == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The float nan will be tranformed to String 'nan'\n",
    "# Use the below assertion carefully when dealing with extra-large datasets\n",
    "assert cat_df.isnull().equals(cat_df_obj.isin({'nan'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no NA left\n",
    "assert all(cat_df_obj.isnull().sum())==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with special columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'nan' with 'not specified' in column 'FONDKAPREMONT_MODE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the replacement and re-assign the modified column back to the original dataframe\n",
    "cat_df_obj['FONDKAPREMONT_MODE'] = cat_df_obj['FONDKAPREMONT_MODE'].replace('nan','not specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the unique value, it should be 1 less than the original cat_df\n",
    "assert cat_df['FONDKAPREMONT_MODE'].unique().size == cat_df_obj['FONDKAPREMONT_MODE'].unique().size +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the input dataframe (i.e., cat_df_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 73)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df_obj.apply(lambda x:x.unique().size).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 833)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.get_dummies() method deals only with categorical variables.\n",
    "# Although it has a built-in argument 'dummy_na' to manage the na value, \n",
    "# our na value has already been converted to string object which are not recognized by the method.\n",
    "# Let's just move forward as planned\n",
    "cat_df_obj_ohe = pd.get_dummies(cat_df_obj, drop_first=True)\n",
    "cat_df_obj_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the ohe is successful\n",
    "assert np.all(np.isin(cat_df_obj_ohe.values,[0,1])) == True\n",
    "# cat_df_obj_ohe.dtypes\n",
    "assert np.all(cat_df_obj_ohe.dtypes) == 'uint8'\n",
    "# make sure the column counts are correct\n",
    "assert cat_df_obj.apply(lambda x:x.unique().size).sum() == cat_df_obj_ohe.shape[1] + cat_df_obj.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit np.isin(cat_df_obj_ohe.values,[0,1])\n",
    "# # 1.86 s ± 133 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit cat_df_obj_ohe.isin([0 , 1])\n",
    "# # 3.38 s ± 32.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit np.all(np.isin(cat_df_obj_ohe.values,[0,1]))\n",
    "# # 1.85 s ± 28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit np.all(cat_df_obj_ohe.isin([0 , 1]))\n",
    "# # 3.47 s ± 193 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with numerial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get na flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 47)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns contain na value.\n",
    "num_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df = num_df[num_df.columns[num_df.isna().any()]]\n",
    "num_notna_df = num_df[num_df.columns[num_df.notna().all()]]\n",
    "num_isna_df.shape, num_notna_df.shape\n",
    "assert num_isna_df.shape[1] + num_notna_df.shape[1] == num_df.shape[1]\n",
    "assert num_isna_df.shape[0] == num_notna_df.shape[0] == num_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 41)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_df.isna().any(): column names for those na containing columns\n",
    "# use it to transform values bool to int, and then add suffix on the column names to get the na-flag df\n",
    "num_naFlag_df = num_isna_df.isna().astype(int).add_suffix('_na')\n",
    "num_naFlag_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace na with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 41)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_isna_df = num_isna_df.fillna(0)\n",
    "num_isna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_isna_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_isna_df.shape == num_naFlag_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.concat([num_notna_df,num_isna_df,num_naFlag_df], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_notna_df.shape[1] + num_isna_df.shape[1] + num_naFlag_df.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356255 entries, 0 to 356254\n",
      "Columns: 88 entries, AMT_INCOME_TOTAL to DAYS_LAST_PHONE_CHANGE_na\n",
      "dtypes: float64(44), int32(41), int64(3)\n",
      "memory usage: 183.5 MB\n"
     ]
    }
   ],
   "source": [
    "num_df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization (DO LATER!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generally, in tree-based models, the scale of the features does not matter.\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#normalization\n",
    "https://datascience.stackexchange.com/questions/22036/how-does-lightgbm-deal-with-value-scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine to a complete, processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.array([id_target_df, cat_df_obj_ohe, num_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356255, 2), (356255, 833), (356255, 88))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_target_df.shape, cat_df_obj_ohe.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 923)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_processed_df = pd.concat(frames, axis ='columns')\n",
    "appl_all_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert appl_all_processed_df.shape[1] == id_target_df.shape[1] + cat_df_obj_ohe.shape[1] + num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356255 entries, 0 to 356254\n",
      "Columns: 923 entries, SK_ID_CURR to DAYS_LAST_PHONE_CHANGE_na\n",
      "dtypes: float64(45), int32(41), int64(4), uint8(833)\n",
      "memory usage: 471.9 MB\n"
     ]
    }
   ],
   "source": [
    "appl_all_processed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the 'TARGET' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000    282686\n",
       "1.0000     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_processed_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanceFactor = ((appl_all_processed_df['TARGET'].value_counts()[0])/(appl_all_processed_df['TARGET'].value_counts()[1])).round(0).astype(int)\n",
    "balanceFactor\n",
    "# appl_all_processed_df['TARGET'].value_counts()[0]\n",
    "# appl_all_processed_df['TARGET'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24825, 923)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_df = appl_all_processed_df[appl_all_processed_df['TARGET']==1]\n",
    "default_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248250, 923)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_df_balanced = pd.concat( [default_df] * (balanceFactor - 1), sort=False, ignore_index=True )\n",
    "default_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(604505, 923)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_processed_df_balanced = pd.concat([appl_all_processed_df , default_df_balanced], sort=False, ignore_index=True)\n",
    "appl_all_processed_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0., nan]), (273075, 282686, 48744))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(appl_all_processed_df_balanced['TARGET'].unique(),\n",
    "(appl_all_processed_df_balanced['TARGET'].value_counts()[1], \\\n",
    "appl_all_processed_df_balanced['TARGET'].value_counts()[0], \\\n",
    "appl_all_processed_df_balanced['TARGET'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 604505 entries, 0 to 604504\n",
      "Columns: 923 entries, SK_ID_CURR to DAYS_LAST_PHONE_CHANGE_na\n",
      "dtypes: float64(45), int32(41), int64(4), uint8(833)\n",
      "memory usage: 800.8 MB\n"
     ]
    }
   ],
   "source": [
    "appl_all_processed_df_balanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df_balanced.to_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_appl_all_v2_20200201_balanced.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coded below are not executed (2020/02/01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "* cleaning:\n",
    "    * num_df: normalize with z-score\n",
    "* feature engineering:\n",
    "    * make reciprocol, polynomial columns of the existing columns. 1/x, x^x.\n",
    "    * multiplying each columns, two columns at a time.\n",
    "    * asset items, income items, willingness(history + misc profile) items, loading(principle + interest) items\n",
    "    * Integration from other tables?\n",
    "\n",
    "https://ithelp.ithome.com.tw/articles/10202059\n",
    "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "https://www.kaggle.com/parasjindal96/how-to-normalize-dataframe-pandas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcol = df['CNT_FAM_MEMBERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numcol.describe(), \\\n",
    "numcol.isnull().sum(), \\\n",
    "numcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcol.value_counts(sort=True), numcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numcol_toYear = pd.to_numeric(\\\n",
    "#                               ((numcol.abs() / 365) \\\n",
    "#                                .round(0)) \\\n",
    "#                               ,downcast='integer')\n",
    "# numcol_toYear.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# numcol_toYear.value_counts(sort=True), numcol_toYear.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol = df['HOUR_APPR_PROCESS_START']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.unique(), \\\n",
    "catcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool: Getting summary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might not be very useful at this point\n",
    "def summary_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    summary_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return summary_df\n",
    "\n",
    "def data_quality_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    data_quality_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return data_quality_df.iloc[[11,13,12,0,],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_quality_df(appl_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# data_quality_df(df).to_csv(\"./eda_output/application_train_data_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# summary_df(df).to_csv(\"./eda_output/application_train_summary_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .nunique() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique() function excludes NaN \n",
    "# i.e. it does not consider NaN as a \"value\", therefore NaN is not counted as a \"unique value\"\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() == df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .value_counts() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .value_counts() function has similar viewpoint towards NaN.\n",
    "# i.e. it does not consider null as a value, therefore not counted in .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['NAME_TYPE_SUITE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].value_counts().sum() + df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum() == \\\n",
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重複值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting unique values (cf. .nunique() function, see above section)\n",
    "# This code was retrieved from HT\n",
    "\n",
    "df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the same if you write (df.apply(lambda x:x.unique().size))\n",
    "assert (df.apply(lambda x:x.unique().shape[0])==df.apply(lambda x:x.unique().size)).all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %timeit showed the performances are similar\n",
    "# %timeit df.apply(lambda x:x.unique().shape[0])\n",
    "# %timeit df.apply(lambda x:x.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 含空值欄位占比\n",
    "print(f\"{df.isnull().any().sum()} in {df.shape[1]} columns (ratio: {(df.isnull().any().sum()/df.shape[1]).round(2)}) has empty value(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
