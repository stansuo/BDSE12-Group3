{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Notice: This notebook is not optimized for memory nor performance yet. Please use it with caution when handling large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: Please ignore Feature engineering part if you are using a ready dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for BDSE12_03G_HomeCredit_V2.csv processing for bear LGBM final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare work environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for managing datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.17.4', '0.25.3')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math for operating numbers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change pd displayg format for float\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "#Seaborn set() to set aesthetic parameters in one step.\n",
    "sns.set() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_fteng/BDSE12_03G_HomeCredit_V2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 797 entries, AMT_ANNUITY to GOODS_PRICE_PREV%\n",
      "dtypes: float64(741), int64(42), object(14)\n",
      "memory usage: 2.1+ GB\n"
     ]
    }
   ],
   "source": [
    "appl_all_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appl_all_df.apply(lambda x:x.unique().size).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0., nan]), 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df['TARGET'].unique(), \\\n",
    "appl_all_df['TARGET'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000    282686\n",
       "1.0000     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 356255, 0.1368)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_df['TARGET'].isnull().sum(), \\\n",
    "appl_all_df['TARGET'].size, \\\n",
    "(appl_all_df['TARGET'].isnull().sum()/appl_all_df['TARGET'].size).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we can use the nullness of 'TARGET' column to separate train & test\n",
    "# assert appl_all_df['TARGET'].isnull().sum() == appl_test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized sampleing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the dataset is too large, consider following randomized sampling from original dataset to facilitate development and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized sampling from original dataset.\n",
    "# This is just for simplifying the development process\n",
    "# After coding is complete, should replace all df-->df, and remove this cell\n",
    "# Reference: https://yiidtw.github.io/blog/2018-05-29-how-to-shuffle-dataframe-in-pandas/\n",
    "\n",
    "# df= appl_all_df.sample(n = 1000).reset_index(drop=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiprocessing (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToRead: multi-threading\n",
    "# http://violin-tao.blogspot.com/2017/05/python3_26.html\n",
    "# https://medium.com/@peilee_98185/%E6%94%BE%E9%96%8B%E9%82%A3%E8%A8%98%E6%86%B6%E9%AB%94-%E4%B9%8B-python-%E8%99%95%E7%90%86%E5%A4%A7%E8%B3%87%E6%96%99-84fd41806694\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(2) # 裡面填要開幾核心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.Pool at 0x1984d185d48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pool.map(data_process_function, dfs )\n",
    "# # dfs 為裝了很多 Pandas DataFrame 的 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool: Get numerical/ categorical variables(columns) from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of numerical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with > 3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    num_mask = data_df.apply(lambda x:x.unique().size > unique_value_threshold,axis=0) \n",
    "    num_df = data_df[data_df.columns[num_mask]]\n",
    "    return num_df\n",
    "\n",
    "def get_cat_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of categorical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with =<3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    cat_mask = data_df.apply(lambda x:x.unique().size <= unique_value_threshold,axis=0) \n",
    "    cat_df = data_df[data_df.columns[cat_mask]]\n",
    "    return cat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when doing this assertion with large datasets\n",
    "# assert get_cat_df(appl_all_df, 3).columns.size + get_num_df(appl_all_df, 3).columns.size == appl_all_df.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting id_target_df, cat_df, num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356255, 797), (356255, 2), (356255, 795))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate id and target columns before any further processing\n",
    "id_target_df = appl_all_df.loc[:, ['SK_ID_CURR','TARGET']]\n",
    "\n",
    "# Get the operating appl_all_df by removing id and target columns\n",
    "appl_all_df_opr = appl_all_df.drop(['SK_ID_CURR','TARGET'], axis=1)\n",
    "\n",
    "# A quick check of their shapes\n",
    "appl_all_df.shape, id_target_df.shape, appl_all_df_opr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the numerical and categorical variable containing columns via the tools decribed above.\n",
    "# Max identified unique value of categorical column 'ORGANIZATION_TYPE' = 58\n",
    "cat_df = get_cat_df (appl_all_df_opr, 58)\n",
    "num_df = get_num_df (appl_all_df_opr, 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 250 entries, AMT_REQ_CREDIT_BUREAU_DAY to AMT_REQ_CREDIT_BUREAU_MON/QRT\n",
      "dtypes: float64(198), int64(38), object(14)\n",
      "memory usage: 682.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 545 entries, AMT_ANNUITY to GOODS_PRICE_PREV%\n",
      "dtypes: float64(542), int64(3)\n",
      "memory usage: 1.4 GB\n"
     ]
    }
   ],
   "source": [
    "cat_df.info()\n",
    "num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'appl_all_df_opr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-4ccf7923aa67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# A quick check of their shapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mappl_all_df_opr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'appl_all_df_opr' is not defined"
     ]
    }
   ],
   "source": [
    "# A quick check of their shapes\n",
    "appl_all_df_opr.shape, cat_df.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cat_df.shape[1] + num_df.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df_opr.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df.shape[1]\n",
    "\n",
    "assert cat_df.shape[0] == num_df.shape[0] == id_target_df.shape[0] \\\n",
    "    == appl_all_df_opr.shape[0] \\\n",
    "    == appl_all_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 795 entries, AMT_ANNUITY to GOODS_PRICE_PREV%\n",
      "dtypes: float64(740), int64(41), object(14)\n",
      "memory usage: 2.1+ GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 797 entries, AMT_ANNUITY to GOODS_PRICE_PREV%\n",
      "dtypes: float64(741), int64(42), object(14)\n",
      "memory usage: 2.1+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "appl_all_df_opr.info()\n",
    "appl_all_df.info()\n",
    "del appl_all_df_opr\n",
    "del appl_all_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to String (i.e., python object) and fill nan with String 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj = cat_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(cat_df_obj.dtypes) == object\n",
    "\n",
    "# There are no NA left\n",
    "assert all(cat_df_obj.isnull().sum())==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The float nan will be tranformed to String 'nan'\n",
    "# Use this assertion carefully when dealing with extra-large datasets\n",
    "assert cat_df.isnull().equals(cat_df_obj.isin({'nan'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with special columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'nan' with 'not specified' in column 'FONDKAPREMONT_MODE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the replacement and re-assign the modified column back to the original dataframe\n",
    "cat_df_obj['FONDKAPREMONT_MODE'] = cat_df_obj['FONDKAPREMONT_MODE'].replace('nan','not specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the unique value, it should be 1 less than the original cat_df\n",
    "assert cat_df['FONDKAPREMONT_MODE'].unique().size == cat_df_obj['FONDKAPREMONT_MODE'].unique().size +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 250 entries, AMT_REQ_CREDIT_BUREAU_DAY to AMT_REQ_CREDIT_BUREAU_MON/QRT\n",
      "dtypes: float64(198), int64(38), object(14)\n",
      "memory usage: 682.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "cat_df.info()\n",
    "del cat_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR/QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR/YEAR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY/WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY/MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY/QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY/YEAR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK/MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK/QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK/YEAR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON/QRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          9                           5   \n",
       "4                          0                           0   \n",
       "5                          0                           0   \n",
       "6                          0                           0   \n",
       "7                          0                           0   \n",
       "8                          0                           0   \n",
       "9                          9                           5   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                         24                         11   \n",
       "4                          0                          0   \n",
       "5                          0                          1   \n",
       "6                          1                          1   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                         24                         11   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_YEAR  CNT_CHILDREN  \\\n",
       "0                           0                           1             0   \n",
       "1                           0                           0             0   \n",
       "2                           0                           0             0   \n",
       "3                           9                          25             0   \n",
       "4                           0                           0             0   \n",
       "5                           0                           1             0   \n",
       "6                           0                          12             1   \n",
       "7                           0                           0             0   \n",
       "8                           0                           1             0   \n",
       "9                           9                          25             0   \n",
       "\n",
       "   CNT_FAM_MEMBERS  CODE_GENDER  DEF_30_CNT_SOCIAL_CIRCLE  ...  \\\n",
       "0                0            1                         2  ...   \n",
       "1                8            0                         0  ...   \n",
       "2                0            1                         0  ...   \n",
       "3                8            0                         0  ...   \n",
       "4                0            1                         0  ...   \n",
       "5                8            1                         0  ...   \n",
       "6               11            0                         0  ...   \n",
       "7                8            1                         0  ...   \n",
       "8                8            0                         0  ...   \n",
       "9                0            1                         0  ...   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_HOUR/QRT  AMT_REQ_CREDIT_BUREAU_HOUR/YEAR  \\\n",
       "0                               9                                0   \n",
       "1                               9                               20   \n",
       "2                               9                               20   \n",
       "3                               9                               20   \n",
       "4                               9                               20   \n",
       "5                               0                                0   \n",
       "6                               0                                0   \n",
       "7                               9                               20   \n",
       "8                               9                                0   \n",
       "9                               9                               20   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY/WEEK  AMT_REQ_CREDIT_BUREAU_DAY/MON  \\\n",
       "0                              16                             16   \n",
       "1                              16                             16   \n",
       "2                              16                             16   \n",
       "3                              16                             16   \n",
       "4                              16                             16   \n",
       "5                              16                             16   \n",
       "6                              16                              0   \n",
       "7                              16                             16   \n",
       "8                              16                             16   \n",
       "9                              16                             16   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY/QRT  AMT_REQ_CREDIT_BUREAU_DAY/YEAR  \\\n",
       "0                             12                               0   \n",
       "1                             12                              30   \n",
       "2                             12                              30   \n",
       "3                             12                              30   \n",
       "4                             12                              30   \n",
       "5                              0                               0   \n",
       "6                              0                               0   \n",
       "7                             12                              30   \n",
       "8                             12                               0   \n",
       "9                             12                              30   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK/MON  AMT_REQ_CREDIT_BUREAU_WEEK/QRT  \\\n",
       "0                              25                              15   \n",
       "1                              25                              15   \n",
       "2                              25                              15   \n",
       "3                              25                              15   \n",
       "4                              25                              15   \n",
       "5                              25                               0   \n",
       "6                               0                               0   \n",
       "7                              25                              15   \n",
       "8                              25                              15   \n",
       "9                              25                              15   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK/YEAR  AMT_REQ_CREDIT_BUREAU_MON/QRT  \n",
       "0                                0                             46  \n",
       "1                               39                             46  \n",
       "2                               39                             46  \n",
       "3                               39                             46  \n",
       "4                               39                             46  \n",
       "5                                0                              0  \n",
       "6                                0                             13  \n",
       "7                               39                             46  \n",
       "8                                0                             46  \n",
       "9                               39                             46  \n",
       "\n",
       "[10 rows x 250 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply le on categorical feature columns\n",
    "cat_df_obj_le = cat_df_obj[:].apply(lambda col: le.fit_transform(col))\n",
    "cat_df_obj_le.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 250 entries, AMT_REQ_CREDIT_BUREAU_DAY to AMT_REQ_CREDIT_BUREAU_MON/QRT\n",
      "dtypes: int64(250)\n",
      "memory usage: 682.2 MB\n"
     ]
    }
   ],
   "source": [
    "cat_df_obj_le.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert all(cat_df_obj_le == cat_df_obj)\n",
    "assert cat_df_obj_le.shape[1] == cat_df_obj.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cat_df_obj\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the input dataframe (i.e., cat_df_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cat_df_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cat_df_obj.apply(lambda x:x.unique().size).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ?pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pd.get_dummies() method deals only with categorical variables.\n",
    "# Although it has a built-in argument 'dummy_na' to manage the na value, \n",
    "# our na value has already been converted to string object which are not recognized by the method.\n",
    "# Let's just move forward as planned\n",
    "cat_df_obj_ohe = pd.get_dummies(cat_df_obj, drop_first=True)\n",
    "cat_df_obj_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Make sure the ohe is successful\n",
    "# assert np.all(np.isin(cat_df_obj_ohe.values,[0,1])) == True\n",
    "# # cat_df_obj_ohe.dtypes\n",
    "# assert np.all(cat_df_obj_ohe.dtypes) == 'uint8'\n",
    "# # make sure the column counts are correct\n",
    "# assert cat_df_obj.apply(lambda x:x.unique().size).sum() == cat_df_obj_ohe.shape[1] + cat_df_obj.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cat_df_obj_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Apply the following gc if memory is running slow\n",
    "# del cat_df_obj\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %timeit np.isin(cat_df_obj_ohe.values,[0,1])\n",
    "# # 1.86 s ± 133 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit cat_df_obj_ohe.isin([0 , 1])\n",
    "# # 3.38 s ± 32.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %timeit np.all(np.isin(cat_df_obj_ohe.values,[0,1]))\n",
    "# # 1.85 s ± 28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit np.all(cat_df_obj_ohe.isin([0 , 1]))\n",
    "# # 3.47 s ± 193 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with numerial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get na flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 545)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns contain na value.\n",
    "num_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df = num_df[num_df.columns[num_df.isna().any()]]\n",
    "num_notna_df = num_df[num_df.columns[num_df.notna().all()]]\n",
    "\n",
    "assert num_isna_df.shape[1] + num_notna_df.shape[1] == num_df.shape[1]\n",
    "assert num_isna_df.shape[0] == num_notna_df.shape[0] == num_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356255, 528), (356255, 17))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_isna_df.shape, num_notna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 528 entries, APARTMENTS_AVG_na to GOODS_PRICE_PREV%_na\n",
      "dtypes: uint8(528)\n",
      "memory usage: 182.1 MB\n"
     ]
    }
   ],
   "source": [
    "# num_df.isna().any(): column names for those na containing columns\n",
    "# use it to transform values bool to int, and then add suffix on the column names to get the na-flag df\n",
    "num_naFlag_df = num_isna_df.isna().astype(np.uint8).add_suffix('_na')\n",
    "num_naFlag_df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace na with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 528)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_isna_df = num_isna_df.fillna(0)\n",
    "num_isna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns contain na value.\n",
    "num_isna_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 528 entries, APARTMENTS_AVG to GOODS_PRICE_PREV%\n",
      "dtypes: float64(528)\n",
      "memory usage: 1.4 GB\n"
     ]
    }
   ],
   "source": [
    "num_isna_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_isna_df.shape == num_naFlag_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.concat([num_notna_df,num_isna_df,num_naFlag_df], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_notna_df.shape[1] + num_isna_df.shape[1] + num_naFlag_df.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 1073 entries, AMT_ANNUITY to GOODS_PRICE_PREV%_na\n",
      "dtypes: float64(542), int64(3), uint8(528)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "num_df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del num_notna_df\n",
    "del num_isna_df\n",
    "del num_naFlag_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization (DO LATER!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generally, in tree-based models, the scale of the features does not matter.\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#normalization\n",
    "https://datascience.stackexchange.com/questions/22036/how-does-lightgbm-deal-with-value-scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine to a complete, processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.array([id_target_df, cat_df_obj_le, num_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356255, 2), (356255, 250), (356255, 1073))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_target_df.shape, cat_df_obj_le.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 1325)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appl_all_processed_df = pd.concat(frames, axis ='columns')\n",
    "appl_all_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert appl_all_processed_df.shape[1] == id_target_df.shape[1] + cat_df_obj_le.shape[1] + num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 1325 entries, SK_ID_CURR to GOODS_PRICE_PREV%_na\n",
      "dtypes: float64(543), int64(254), uint8(528)\n",
      "memory usage: 2.3 GB\n"
     ]
    }
   ],
   "source": [
    "appl_all_processed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del id_target_df\n",
    "del cat_df_obj_le\n",
    "del num_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the dataframe to csv for future use\n",
    "# appl_all_processed_df.to_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_fromBDSE12_03G_HomeCredit_V2_le_20200210a.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the dtypes Series to csv for future use\n",
    "# appl_all_processed_df.dtypes.to_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_fromBDSE12_03G_HomeCredit_V2_le_20200210a_dtypes_series.csv', header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface connecting fteng & model parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign appl_all_processed_df to final_df for follow-up modeling\n",
    "final_df = appl_all_processed_df\n",
    "\n",
    "# Apply the following gc if memory is running slow\n",
    "del appl_all_processed_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in final_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 356254\n",
      "Columns: 1325 entries, SK_ID_CURR to GOODS_PRICE_PREV__na\n",
      "dtypes: float64(543), int64(254), uint8(528)\n",
      "memory usage: 2.3 GB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling part. If using a ready dataset, please start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the saved dtypes Series\n",
    "final_df_dtypes = \\\n",
    "pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_fromBDSE12_03G_HomeCredit_V2_le_20200210a_dtypes_series.csv'\\\n",
    "            , header=None, index_col=0, squeeze=True)\n",
    "del final_df_dtypes.index.name\n",
    "final_df_dtypes = final_df_dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = \\\n",
    "pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_fromBDSE12_03G_HomeCredit_V2_le_20200210a.csv'\\\n",
    "           , dtype= final_df_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in final_df.columns]\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following is based on 'bear_Final_model' released 2020/01/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forked from excellent kernel : https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features\n",
    "# From Kaggler : https://www.kaggle.com/jsaguiar\n",
    "# Just added a few features so I thought I had to make release it as well...\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df['TARGET'].isna().sum(), \n",
    "      final_df['TARGET'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['TARGET'].isnull().sum(), \\\n",
    "final_df['TARGET'].size, \\\n",
    "(final_df['TARGET'].isnull().sum()/final_df['TARGET'].size).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'scale_pos_weight'\n",
    "282686/24825 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取參數檔案\n",
    "import json\n",
    "with open('../../../BDSE12-Group3/datasets/homecdt_ss_output/params_list_BayesOpt_20200206a.txt', 'r', encoding='utf-8') as f:\n",
    "    params_list_read = list(map(json.loads,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_list_read\n",
    "params_list_read[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "def kfold_lightgbm(df, num_folds = 5, stratified = True, debug= False, boosting_type= 'goss', epoch=20000, early_stop=200):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM goss. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=924)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=924)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                             label=train_df['TARGET'].iloc[train_idx], \n",
    "                             free_raw_data=False, silent=True)\n",
    "        dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                             label=train_df['TARGET'].iloc[valid_idx], \n",
    "                             free_raw_data=False, silent=True)\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "\n",
    "# params_list_BayesOpt_20200206a.txt[8]\n",
    "# {'target': 0.7932865050364686,\n",
    "#  'params': {'learning_rate': 0.01470849186434721,\n",
    "#   'max_bin': 142.66101896998015,\n",
    "#   'max_depth': 27.91451741057181,\n",
    "#   'min_child_weight': 31.702341834307422,\n",
    "#   'min_data_in_leaf': 50.05967985991292,\n",
    "#   'min_split_gain': 0.09320570777639621,\n",
    "#   'num_leaves': 44.20174344127514,\n",
    "#   'reg_alpha': 0.7786108741002781,\n",
    "#   'reg_lambda': 0.3782185675928136,\n",
    "#   'subsample': 0.9556663511637553}}\n",
    "        params = {\n",
    "            'learning_rate': 0.01470849186434721,\n",
    "            'max_bin': 143,\n",
    "            'max_depth': 28,\n",
    "            'min_child_weight': 31.702341834307422,\n",
    "            'min_data_in_leaf': 50,\n",
    "            'min_split_gain': 0.09320570777639621,\n",
    "            'num_leaves': 44,\n",
    "            'reg_alpha': 0.7786108741002781,\n",
    "            'reg_lambda': 0.3782185675928136,\n",
    "            'subsample': 0.9556663511637553,\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': boosting_type,\n",
    "            'nthread': 2,\n",
    "            'scale_pos_weight': 11.387150050352467,\n",
    "            'seed': 924,\n",
    "            'verbose': 2000,\n",
    "            'metric': 'auc',\n",
    "            \n",
    "#             'tree_learner': 'voting',\n",
    "#             'colsample_bytree': 0.9497036,\n",
    "#             'subsample_freq': 0,          \n",
    "#             'histogram_pool_size': 20480\n",
    "#             'device' : 'gpu',\n",
    "#             'gpu_platform_id': 0,\n",
    "#             'gpu_device_id':0\n",
    "        }\n",
    "        \n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=epoch,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            early_stopping_rounds=early_stop,\n",
    "            verbose_eval=2000\n",
    "        )\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "        sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(dvalid.label, oof_preds[valid_idx])))\n",
    "        del clf, dtrain, dvalid\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        sub_df = test_df[['SK_ID_CURR']].copy()\n",
    "        sub_df['TARGET'] = sub_preds\n",
    "        sub_df[['SK_ID_CURR', 'TARGET']].to_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/homecdt_submission_LGBM.csv', index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout\n",
    "    plt.savefig('../../../BDSE12-Group3/datasets/homecdt_ss_output/lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：goss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "kfold_lightgbm(final_df,10)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "kfold_lightgbm(final_df,10)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_time = time.time()\n",
    "# kfold_lightgbm(final_df, 10, boosting_type= 'gbdt')\n",
    "# print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_time = time.time()\n",
    "# kfold_lightgbm(final_df,10, boosting_type= 'dart')\n",
    "# print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_time = time.time()\n",
    "# kfold_lightgbm(final_df,10,boosting_type= 'rf')\n",
    "# print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_xgb(df, num_folds, stratified = True, debug= False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting XGBoost. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1054)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1054)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        #if n_fold == 0: # REmove for full K-fold run\n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf = XGBClassifier(learning_rate =0.01, \n",
    "                            n_estimators=5000, \n",
    "                            max_depth=4, \n",
    "                            min_child_weight=5,\n",
    "#                             tree_method='gpu_hist',\n",
    "                            subsample=0.8, \n",
    "                            colsample_bytree=0.8, \n",
    "                            objective= 'binary:logistic',\n",
    "                            nthread=4,\n",
    "                            scale_pos_weight=2.5,\n",
    "                            seed=28,\n",
    "                            reg_lambda = 1.2)\n",
    "        \n",
    "#         clf = pickle.load(open('test.pickle','rb'))\n",
    "        \n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 1000, early_stopping_rounds= 200)\n",
    "        \n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        \n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats])[:, 1] # / folds.n_splits # - Uncomment for K-fold \n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "        np.save(\"xgb_oof_preds_1\", oof_preds)\n",
    "        np.save(\"xgb_sub_preds_1\", sub_preds)\n",
    "        \n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        \n",
    "    \n",
    "    clf = pickle.load(open('test.pickle','rb'))\n",
    "    # print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv('submission_XGBoost_GPU.csv', index= False)\n",
    "    #display_importances(feature_importance_df)\n",
    "    #return feature_importance_df\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('XGBoost Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('xgb_importances02.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "kfold_xgb(final_df, 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below not executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the 'TARGET' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "appl_all_processed_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "balanceFactor = ((appl_all_processed_df['TARGET'].value_counts()[0])/(appl_all_processed_df['TARGET'].value_counts()[1])).round(0).astype(int)\n",
    "balanceFactor\n",
    "# appl_all_processed_df['TARGET'].value_counts()[0]\n",
    "# appl_all_processed_df['TARGET'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "default_df = appl_all_processed_df[appl_all_processed_df['TARGET']==1]\n",
    "default_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "default_df_balanced = pd.concat( [default_df] * (balanceFactor - 1), sort=False, ignore_index=True )\n",
    "default_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "appl_all_processed_df_balanced = pd.concat([appl_all_processed_df , default_df_balanced], sort=False, ignore_index=True)\n",
    "appl_all_processed_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(appl_all_processed_df_balanced['TARGET'].unique(),\n",
    "(appl_all_processed_df_balanced['TARGET'].value_counts()[1], \\\n",
    "appl_all_processed_df_balanced['TARGET'].value_counts()[0], \\\n",
    "appl_all_processed_df_balanced['TARGET'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del appl_all_processed_df_balanced\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Todo:\n",
    "* cleaning:\n",
    "    * num_df: normalize with z-score\n",
    "* feature engineering:\n",
    "    * make reciprocol, polynomial columns of the existing columns. 1/x, x^x.\n",
    "    * multiplying each columns, two columns at a time.\n",
    "    * asset items, income items, willingness(history + misc profile) items, loading(principle + interest) items\n",
    "    * Integration from other tables?\n",
    "\n",
    "https://ithelp.ithome.com.tw/articles/10202059\n",
    "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "https://www.kaggle.com/parasjindal96/how-to-normalize-dataframe-pandas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "numcol = df['CNT_FAM_MEMBERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numcol.describe(), \\\n",
    "numcol.isnull().sum(), \\\n",
    "numcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "numcol.value_counts(sort=True), numcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# numcol_toYear = pd.to_numeric(\\\n",
    "#                               ((numcol.abs() / 365) \\\n",
    "#                                .round(0)) \\\n",
    "#                               ,downcast='integer')\n",
    "# numcol_toYear.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# numcol_toYear.value_counts(sort=True), numcol_toYear.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catcol = df['HOUR_APPR_PROCESS_START']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catcol.unique(), \\\n",
    "catcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catcol.value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool: Getting summary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# might not be very useful at this point\n",
    "def summary_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    summary_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return summary_df\n",
    "\n",
    "def data_quality_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    data_quality_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return data_quality_df.iloc[[11,13,12,0,],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_quality_df(appl_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# data_quality_df(df).to_csv(\"./eda_output/application_train_data_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# summary_df(df).to_csv(\"./eda_output/application_train_summary_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .nunique() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# nunique() function excludes NaN \n",
    "# i.e. it does not consider NaN as a \"value\", therefore NaN is not counted as a \"unique value\"\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.nunique() == df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .value_counts() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# .value_counts() function has similar viewpoint towards NaN.\n",
    "# i.e. it does not consider null as a value, therefore not counted in .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['NAME_TYPE_SUITE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].value_counts().sum() + df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum() == \\\n",
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重複值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Counting unique values (cf. .nunique() function, see above section)\n",
    "# This code was retrieved from HT\n",
    "\n",
    "df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# It is the same if you write (df.apply(lambda x:x.unique().size))\n",
    "assert (df.apply(lambda x:x.unique().shape[0])==df.apply(lambda x:x.unique().size)).all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # %timeit showed the performances are similar\n",
    "# %timeit df.apply(lambda x:x.unique().shape[0])\n",
    "# %timeit df.apply(lambda x:x.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 含空值欄位占比\n",
    "print(f\"{df.isnull().any().sum()} in {df.shape[1]} columns (ratio: {(df.isnull().any().sum()/df.shape[1]).round(2)}) has empty value(s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-casting to reduce memory use (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isfinite(num_df).all().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite = num_df[num_df.columns[np.isfinite(num_df).all()]]\n",
    "# num_df_infinite = num_df[num_df.columns[np.isfinite(num_df).all() == False]]\n",
    "# num_df_finite.shape, num_df_infinite.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert num_df_finite.shape[0] == num_df_infinite.shape[0] == num_df.shape[0]\n",
    "# assert num_df_finite.shape[1] + num_df_infinite.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_mem_usage(props, finite:bool = True):\n",
    "#     props.info(verbose=False)\n",
    "#     start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "#     print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "#     if finite == True:  \n",
    "#         props[props.columns[(props.min()>=0) & (props.max()<255)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) & (props.max()<255)]].astype(np.uint8, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 255) & (props.max()<65535)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 255) & (props.max()<65535)]] \\\n",
    "#         .astype(np.uint16, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 65535) & (props.max()<4294967295)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 65535) & (props.max()<4294967295)]] \\\n",
    "#         .astype(np.uint32, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 4294967295)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 4294967295)]] \\\n",
    "#         .astype(np.uint64, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "#     else:\n",
    "#         props = props.astype(np.float32, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "        \n",
    "#     print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "#     mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "#     print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "#     print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    \n",
    "#     return props\n",
    "\n",
    "# if num_na_df_finite.min()>=0:\n",
    "#     if num_na_df_finite.max() < 255:\n",
    "#         props[col] = props[col].astype(np.uint8)\n",
    "#     elif num_na_df_finite.max() < 65535:\n",
    "#         props[col] = props[col].astype(np.uint16)\n",
    "#     elif num_na_df_finite.max() < 4294967295:\n",
    "#         props[col] = props[col].astype(np.uint32)\n",
    "#     else:\n",
    "#         props[col] = props[col].astype(np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite = reduce_mem_usage(num_df_finite, finite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_infinite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_infinite = reduce_mem_usage(num_df_infinite, finite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df = pd.concat([num_df_finite, num_df_infinite], axis ='columns')\n",
    "# num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert num_df_finite.shape[0] == num_df_infinite.shape[0] == num_df.shape[0]\n",
    "# assert num_df_finite.shape[1] + num_df_infinite.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# del num_df_finite\n",
    "# del num_df_infinite\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
