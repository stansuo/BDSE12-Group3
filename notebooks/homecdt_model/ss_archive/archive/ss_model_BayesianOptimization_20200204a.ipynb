{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge bayesian-optimization\n",
    "# conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the saved dtypes Series\n",
    "final_df_dtypes = \\\n",
    "pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_fromBDSE12_03G_HomeCredit_V2_20200204a_dtypes_series.csv'\\\n",
    "            , header=None, index_col=0, squeeze=True)\n",
    "del final_df_dtypes.index.name\n",
    "final_df_dtypes = final_df_dtypes.to_dict()\n",
    "\n",
    "final_df = \\\n",
    "pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_fromBDSE12_03G_HomeCredit_V2_20200204a.csv'\\\n",
    "           , dtype= final_df_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356255 entries, 0 to 356254\n",
      "Columns: 4081 entries, SK_ID_CURR to GOODS_PRICE_PREV__na\n",
      "dtypes: float64(543), int64(4), uint8(3534)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "final_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in final_df.columns]\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 356255 entries, 0 to 356254\n",
      "Columns: 4081 entries, SK_ID_CURR to GOODS_PRICE_PREV__na\n",
      "dtypes: float64(543), int64(4), uint8(3534)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "df = final_df\n",
    "del final_df\n",
    "gc.collect()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356255"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_data_in_leaf'] = int(params['min_data_in_leaf'])\n",
    "    params['max_bin'] = int(params['max_bin'])\n",
    "    \n",
    "        \n",
    "    clf = LGBMClassifier(**params, \n",
    "                         n_estimators = 2000,\n",
    "                         nthread = 2, \n",
    "                         boosting_type='goss', \n",
    "                         objective='binary')\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... |  max_bin  | max_depth | min_ch... | min_da... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.05903 \u001b[0m | \u001b[0m 61.23   \u001b[0m | \u001b[0m 17.37   \u001b[0m | \u001b[0m 65.25   \u001b[0m | \u001b[0m 46.36   \u001b[0m | \u001b[0m 0.08632 \u001b[0m | \u001b[0m 93.76   \u001b[0m | \u001b[0m 0.3375  \u001b[0m | \u001b[0m 0.498   \u001b[0m | \u001b[0m 0.7041  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7921  \u001b[0m | \u001b[95m 0.03028 \u001b[0m | \u001b[95m 180.7   \u001b[0m | \u001b[95m 9.954   \u001b[0m | \u001b[95m 53.15   \u001b[0m | \u001b[95m 61.11   \u001b[0m | \u001b[95m 0.06647 \u001b[0m | \u001b[95m 98.39   \u001b[0m | \u001b[95m 0.6436  \u001b[0m | \u001b[95m 0.8446  \u001b[0m | \u001b[95m 0.7006  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7917  \u001b[0m | \u001b[0m 0.04233 \u001b[0m | \u001b[0m 117.3   \u001b[0m | \u001b[0m 18.25   \u001b[0m | \u001b[0m 53.07   \u001b[0m | \u001b[0m 60.75   \u001b[0m | \u001b[0m 0.04874 \u001b[0m | \u001b[0m 21.95   \u001b[0m | \u001b[0m 0.8439  \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.9274  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7906  \u001b[0m | \u001b[0m 0.05174 \u001b[0m | \u001b[0m 192.4   \u001b[0m | \u001b[0m 11.27   \u001b[0m | \u001b[0m 64.21   \u001b[0m | \u001b[0m 26.02   \u001b[0m | \u001b[0m 0.01801 \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.8776  \u001b[0m | \u001b[0m 0.5691  \u001b[0m | \u001b[0m 0.8422  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7932  \u001b[0m | \u001b[95m 0.0169  \u001b[0m | \u001b[95m 235.9   \u001b[0m | \u001b[95m 9.243   \u001b[0m | \u001b[95m 27.64   \u001b[0m | \u001b[95m 43.41   \u001b[0m | \u001b[95m 0.04989 \u001b[0m | \u001b[95m 31.49   \u001b[0m | \u001b[95m 0.9668  \u001b[0m | \u001b[95m 0.4193  \u001b[0m | \u001b[95m 0.7759  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7927  \u001b[0m | \u001b[0m 0.02728 \u001b[0m | \u001b[0m 252.7   \u001b[0m | \u001b[0m 19.94   \u001b[0m | \u001b[0m 20.87   \u001b[0m | \u001b[0m 68.98   \u001b[0m | \u001b[0m 0.04938 \u001b[0m | \u001b[0m 23.03   \u001b[0m | \u001b[0m 0.9108  \u001b[0m | \u001b[0m 0.1542  \u001b[0m | \u001b[0m 0.7997  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7864  \u001b[0m | \u001b[0m 0.08918 \u001b[0m | \u001b[0m 254.9   \u001b[0m | \u001b[0m 8.021   \u001b[0m | \u001b[0m 20.44   \u001b[0m | \u001b[0m 69.33   \u001b[0m | \u001b[0m 0.0578  \u001b[0m | \u001b[0m 90.02   \u001b[0m | \u001b[0m 0.2497  \u001b[0m | \u001b[0m 0.7341  \u001b[0m | \u001b[0m 0.8374  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7898  \u001b[0m | \u001b[0m 0.08918 \u001b[0m | \u001b[0m 251.8   \u001b[0m | \u001b[0m 13.34   \u001b[0m | \u001b[0m 68.51   \u001b[0m | \u001b[0m 64.07   \u001b[0m | \u001b[0m 0.02248 \u001b[0m | \u001b[0m 21.26   \u001b[0m | \u001b[0m 0.9089  \u001b[0m | \u001b[0m 0.7504  \u001b[0m | \u001b[0m 0.9311  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7913  \u001b[0m | \u001b[0m 0.0489  \u001b[0m | \u001b[0m 57.61   \u001b[0m | \u001b[0m 8.862   \u001b[0m | \u001b[0m 21.15   \u001b[0m | \u001b[0m 22.71   \u001b[0m | \u001b[0m 0.02968 \u001b[0m | \u001b[0m 21.85   \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 0.2284  \u001b[0m | \u001b[0m 0.8533  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.7932  \u001b[0m | \u001b[95m 0.01774 \u001b[0m | \u001b[95m 252.7   \u001b[0m | \u001b[95m 15.2    \u001b[0m | \u001b[95m 24.91   \u001b[0m | \u001b[95m 20.68   \u001b[0m | \u001b[95m 0.06798 \u001b[0m | \u001b[95m 21.84   \u001b[0m | \u001b[95m 0.5614  \u001b[0m | \u001b[95m 0.3956  \u001b[0m | \u001b[95m 0.8548  \u001b[0m |\n",
      "=================================================================================================================================================\n",
      "Elapsed time=7364.99 sec.\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.01, .1), \n",
    "          'num_leaves': (21, 99), \n",
    "          'subsample': (0.7, 1), \n",
    "          'max_depth': (6, 21), \n",
    "          'reg_alpha': (.00, 1.0), \n",
    "          'reg_lambda': (.00, 1.0), \n",
    "          'min_split_gain': (.01, .1),\n",
    "          'min_child_weight': (20, 70),\n",
    "          'min_data_in_leaf': (20, 70),\n",
    "          'max_bin': (55, 255)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7926897120749998,\n",
       " 'params': {'learning_rate': 0.027277797382058662,\n",
       "  'max_bin': 252.71833139557864,\n",
       "  'max_depth': 19.94051833524931,\n",
       "  'min_child_weight': 20.868586608046186,\n",
       "  'min_data_in_leaf': 68.98157854879867,\n",
       "  'min_split_gain': 0.04938251335634182,\n",
       "  'num_leaves': 23.027556285612434,\n",
       "  'reg_alpha': 0.9107785355990146,\n",
       "  'reg_lambda': 0.15418005208807806,\n",
       "  'subsample': 0.7997032951619153}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.res[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.0, .1), \n",
    "          'num_leaves': (20, 100), \n",
    "          'subsample': (.0, 1.0), \n",
    "          'max_depth': (6, 9), \n",
    "          'reg_alpha': (.00, 1.0), \n",
    "          'reg_lambda': (.00, 1.0), \n",
    "          'min_split_gain': (.0, .1),\n",
    "          'min_child_weight': (20, 70)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 10)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo.res[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = XGBClassifier(**params, \n",
    "                        n_estimators = 2000, \n",
    "                        nthread = 5, \n",
    "                        objective= 'binary:logistic')\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.01, .03), \n",
    "          'subsample': (.0, 1.0), \n",
    "          'max_depth': (4, 9), \n",
    "          'reg_alpha': (.0, 1.0), \n",
    "          'reg_lambda': (.0, 1.0), \n",
    "          'scale_pos_weight': (.0, 5.0),\n",
    "          'colsample_bytree': (.0, 1.0)}\n",
    "bo = BayesianOptimization(xgb_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
