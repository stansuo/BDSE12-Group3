{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Notice: This notebook is not optimized for memory nor performance yet. Please use it with caution when handling large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: Please ignore Feature engineering part if you are using a ready dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for BDSE12_03G_HomeCredit_V2.csv processing for bear LGBM final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding le for categorical and reciprocal for numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare work environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for managing datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.18.1', '0.25.3')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math for operating numbers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change pd displayg format for float\n",
    "pd.options.display.float_format = '{:,.8f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "#Seaborn set() to set aesthetic parameters in one step.\n",
    "sns.set() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df = pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_fteng/BDSE12_03G_HomeCredit_V3.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appl_all_df.apply(lambda x:x.unique().size).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df['TARGET'].unique(), \\\n",
    "appl_all_df['TARGET'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_df['TARGET'].isnull().sum(), \\\n",
    "appl_all_df['TARGET'].size, \\\n",
    "(appl_all_df['TARGET'].isnull().sum()/appl_all_df['TARGET'].size).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we can use the nullness of 'TARGET' column to separate train & test\n",
    "# assert appl_all_df['TARGET'].isnull().sum() == appl_test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized sampleing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the dataset is too large, consider following randomized sampling from original dataset to facilitate development and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized sampling from original dataset.\n",
    "# This is just for simplifying the development process\n",
    "# After coding is complete, should replace all df-->df, and remove this cell\n",
    "# Reference: https://yiidtw.github.io/blog/2018-05-29-how-to-shuffle-dataframe-in-pandas/\n",
    "\n",
    "# df= appl_all_df.sample(n = 1000).reset_index(drop=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiprocessing (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToRead: multi-threading\n",
    "# http://violin-tao.blogspot.com/2017/05/python3_26.html\n",
    "# https://medium.com/@peilee_98185/%E6%94%BE%E9%96%8B%E9%82%A3%E8%A8%98%E6%86%B6%E9%AB%94-%E4%B9%8B-python-%E8%99%95%E7%90%86%E5%A4%A7%E8%B3%87%E6%96%99-84fd41806694\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool = mp.Pool(4) # 裡面填要開幾核心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pool.map(data_process_function, dfs )\n",
    "# # dfs 為裝了很多 Pandas DataFrame 的 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool: Get numerical/ categorical variables(columns) from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of numerical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with > 3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    num_mask = data_df.apply(lambda x:x.unique().size > unique_value_threshold,axis=0) \n",
    "    num_df = data_df[data_df.columns[num_mask]]\n",
    "    return num_df\n",
    "\n",
    "def get_cat_df (data_df, unique_value_threshold: int):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with columns of categorical variables from the input dataframe.\n",
    "    Input: \n",
    "        data_df: original dataframe, \n",
    "        unique_value_threshold(int): number of unique values of each column\n",
    "    e.g. If we define a column with =<3 unique values as being numerical variable, unique_value_threshold = 3\n",
    "    \"\"\"\n",
    "    cat_mask = data_df.apply(lambda x:x.unique().size <= unique_value_threshold,axis=0) \n",
    "    cat_df = data_df[data_df.columns[cat_mask]]\n",
    "    return cat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when doing this assertion with large datasets\n",
    "# assert get_cat_df(appl_all_df, 3).columns.size + get_num_df(appl_all_df, 3).columns.size == appl_all_df.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting id_target_df, cat_df, num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate id and target columns before any further processing\n",
    "id_target_df = appl_all_df.loc[:, ['SK_ID_CURR','TARGET']]\n",
    "\n",
    "# Get the operating appl_all_df by removing id and target columns\n",
    "appl_all_df_opr = appl_all_df.drop(['SK_ID_CURR','TARGET'], axis=1)\n",
    "\n",
    "# A quick check of their shapes\n",
    "appl_all_df.shape, id_target_df.shape, appl_all_df_opr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the numerical and categorical variable containing columns via the tools decribed above.\n",
    "# Max identified unique value of categorical column 'ORGANIZATION_TYPE' = 58\n",
    "cat_df = get_cat_df (appl_all_df_opr, 58)\n",
    "num_df = get_num_df (appl_all_df_opr, 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.info()\n",
    "num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick check of their shapes\n",
    "appl_all_df_opr.shape, cat_df.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cat_df.shape[1] + num_df.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df_opr.shape[1] + id_target_df.shape[1] \\\n",
    "    == appl_all_df.shape[1]\n",
    "\n",
    "assert cat_df.shape[0] == num_df.shape[0] == id_target_df.shape[0] \\\n",
    "    == appl_all_df_opr.shape[0] \\\n",
    "    == appl_all_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "appl_all_df_opr.info()\n",
    "appl_all_df.info()\n",
    "del appl_all_df_opr\n",
    "del appl_all_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to String (i.e., python object) and fill nan with String 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj = cat_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(cat_df_obj.dtypes) == object\n",
    "\n",
    "# There are no NA left\n",
    "assert all(cat_df_obj.isnull().sum())==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The float nan will be tranformed to String 'nan'\n",
    "# Use this assertion carefully when dealing with extra-large datasets\n",
    "assert cat_df.isnull().equals(cat_df_obj.isin({'nan'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with special columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'nan' with 'not specified' in column 'FONDKAPREMONT_MODE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the replacement and re-assign the modified column back to the original dataframe\n",
    "cat_df_obj['FONDKAPREMONT_MODE'] = cat_df_obj['FONDKAPREMONT_MODE'].replace('nan','not specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the unique value, it should be 1 less than the original cat_df\n",
    "assert cat_df['FONDKAPREMONT_MODE'].unique().size == cat_df_obj['FONDKAPREMONT_MODE'].unique().size +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "cat_df.info()\n",
    "del cat_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply le on categorical feature columns\n",
    "cat_df_obj_le = cat_df_obj[:].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj_le.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert all(cat_df_obj_le == cat_df_obj)\n",
    "assert cat_df_obj_le.shape[1] == cat_df_obj.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj = cat_df_obj_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_obj.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cat_df_obj_le\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the input dataframe (i.e., cat_df_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_df_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_df_obj.apply(lambda x:x.unique().size).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ?pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.get_dummies() method deals only with categorical variables.\n",
    "# # Although it has a built-in argument 'dummy_na' to manage the na value, \n",
    "# # our na value has already been converted to string object which are not recognized by the method.\n",
    "# # Let's just move forward as planned\n",
    "# cat_df_obj_ohe = pd.get_dummies(cat_df_obj, drop_first=True)\n",
    "# cat_df_obj_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure the ohe is successful\n",
    "# assert np.all(np.isin(cat_df_obj_ohe.values,[0,1])) == True\n",
    "# # cat_df_obj_ohe.dtypes\n",
    "# assert np.all(cat_df_obj_ohe.dtypes) == 'uint8'\n",
    "# # make sure the column counts are correct\n",
    "# assert cat_df_obj.apply(lambda x:x.unique().size).sum() == cat_df_obj_ohe.shape[1] + cat_df_obj.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_df_obj = cat_df_obj_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_df_obj.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the following gc if memory is running slow\n",
    "# del cat_df_obj_ohe\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit np.isin(cat_df_obj_ohe.values,[0,1])\n",
    "# # 1.86 s ± 133 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit cat_df_obj_ohe.isin([0 , 1])\n",
    "# # 3.38 s ± 32.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit np.all(np.isin(cat_df_obj_ohe.values,[0,1]))\n",
    "# # 1.85 s ± 28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# %timeit np.all(cat_df_obj_ohe.isin([0 , 1]))\n",
    "# # 3.47 s ± 193 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with numerial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make reciprocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_reciprocals_df = num_df.rdiv(1).add_suffix('_recip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_reciprocals_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_reciprocals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine original num_df with num_reciprocals_df as a new num_df (to fit in the previous code)\n",
    "# num_df = pd.concat([num_df, num_reciprocals_df], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_reciprocals_df.info()\n",
    "# del num_reciprocals_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get na flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider np.inf as nan\n",
    "# ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many columns contain na value.\n",
    "num_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df = num_df[num_df.columns[num_df.isna().any()]]\n",
    "num_notna_df = num_df[num_df.columns[num_df.notna().all()]]\n",
    "\n",
    "assert num_isna_df.shape[1] + num_notna_df.shape[1] == num_df.shape[1]\n",
    "assert num_isna_df.shape[0] == num_notna_df.shape[0] == num_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df.shape, num_notna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df.isna().any(): column names for those na containing columns\n",
    "# use it to transform values bool to int, and then add suffix on the column names to get the na-flag df\n",
    "num_naFlag_df = num_isna_df.isna().astype(np.uint8).add_suffix('_na')\n",
    "num_naFlag_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_naFlag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace na with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df = num_isna_df.fillna(0)\n",
    "num_isna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many columns contain na value.\n",
    "num_isna_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_isna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_isna_df.shape == num_naFlag_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.concat([num_notna_df,num_isna_df,num_naFlag_df], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_notna_df.shape[1] + num_isna_df.shape[1] + num_naFlag_df.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del num_notna_df\n",
    "del num_isna_df\n",
    "del num_naFlag_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to decide if I should transform all float64 to float32 to save memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an IEEE 754 32-bit base-2 floating-point variable has a maximum value of (2 − 2^(−23)) × 2^(127) ≈ 3.4028235 × 10^(38)\n",
    "# https://en.wikipedia.org/wiki/Single-precision_floating-point_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks fine if converting to float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_float64_df = num_df[num_df.columns[(num_df.dtypes == np.float64)]]\n",
    "num_others_df = num_df[num_df.columns[(num_df.dtypes != np.float64)]]\n",
    "num_float64_df.info()\n",
    "print(\"\")\n",
    "num_others_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_float64_df.shape[1] + num_others_df.shape[1] == num_df.shape[1]\n",
    "assert num_float64_df.shape[0] == num_others_df.shape[0] == num_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_float32_df = num_float64_df.astype(np.float32)\n",
    "num_float32_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_float32_df.shape == num_float64_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.concat([num_float32_df,num_others_df], axis = 'columns')\n",
    "num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(num_df.dtypes != np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del num_float64_df\n",
    "del num_others_df\n",
    "del num_float32_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refs:(revise later)\n",
    "# https://www.kaggle.com/aantonova/797-lgbm-and-bayesian-optimization\n",
    "# for col in data.columns:\n",
    "#     col_type = data[col].dtype\n",
    "    # if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "    #     data[col] = data[col].astype(np.float16)\n",
    "    # elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "    #     data[col] = data[col].astype(np.float32)\n",
    "    # else:\n",
    "    #     data[col] = data[col].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization (DO LATER!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generally, in tree-based models, the scale of the features does not matter.\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#normalization\n",
    "https://datascience.stackexchange.com/questions/22036/how-does-lightgbm-deal-with-value-scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine to a complete, processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.array([id_target_df, cat_df_obj, num_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_target_df.shape, cat_df_obj.shape, num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(frames, axis ='columns')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.shape[1] == id_target_df.shape[1] + cat_df_obj.shape[1] + num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del id_target_df\n",
    "del cat_df_obj\n",
    "del num_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df\n",
    "# gc.collect()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dtypes Series to csv for future use\n",
    "df.dtypes.to_csv('../data/ss_fteng_G3V3_le_20200218b_dtypes_series.csv', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to csv for future use\n",
    "df.to_csv('../data/homecdt_ss_output/ss_fteng_G3V3_le_20200218b.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the saved dtypes Series\n",
    "df_dtypes = \\\n",
    "pd.read_csv('../data/ss_fteng_G3V3_le_20200218b_dtypes_series.csv'\\\n",
    "            , header=None, index_col=0, squeeze=True)\n",
    "del df_dtypes.index.name\n",
    "df_dtypes = df_dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = \\\n",
    "pd.read_csv('../data/ss_fteng_G3V3_le_20200218b.csv'\\\n",
    "           , dtype= df_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fmfn/BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge bayesian-optimization\n",
    "# conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reading the saved dtypes Series\n",
    "# df_dtypes = \\\n",
    "# pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_G3V2_ohe_recip_20200216a_dtypes_series.csv'\\\n",
    "#             , header=None, index_col=0, squeeze=True)\n",
    "# del df_dtypes.index.name\n",
    "# df_dtypes df_dtypes.to_dict()\n",
    "\n",
    "# df = \\\n",
    "# pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_G3V2_ohe_recip_20200216a.csv'\\\n",
    "#            , dtype= df_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in final_df.columns]\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00000000    282686\n",
       "1.00000000     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.387150050352467"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale_pos_weight \n",
    "282686 / 24825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesianOptimization- LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install setuptools wheel numpy scipy \"scikit-learn<=0.21.3\" -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bo\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_child_samples'] = int(params['min_child_samples'])\n",
    "    params['max_bin'] = int(params['max_bin'])\n",
    "#     params['max_drop'] = int(params['max_drop'])\n",
    "    \n",
    "        \n",
    "    clf = LGBMClassifier(**params, \n",
    "#                          n_estimators = 2000,\n",
    "#                          nthread = 2, \n",
    "                         boosting_type='goss',\n",
    "#                          drop_seed = 924,\n",
    "                         objective='binary',\n",
    "                         scale_pos_weight = 11.387150050352467,\n",
    "                         random_state = 924,\n",
    "                         n_jobs = 2,\n",
    "                         silent = False,\n",
    "#                          importance_type (string, optional (default='split')) – \n",
    "#                          The type of feature importance to be filled into feature_importances_. \n",
    "#                          If ‘split’, result contains numbers of times the feature is used in a model. \n",
    "#                          If ‘gain’, result contains total gains of splits which use the feature.\n",
    "                        )\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = StratifiedKFold(n_splits= 10, shuffle=True, random_state=1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 200)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... |  max_bin  | max_depth | min_ch... | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7897  \u001b[0m | \u001b[0m 0.08244 \u001b[0m | \u001b[0m 466.1   \u001b[0m | \u001b[0m 168.8   \u001b[0m | \u001b[0m 264.0   \u001b[0m | \u001b[0m 59.34   \u001b[0m | \u001b[0m 8.029   \u001b[0m | \u001b[0m 54.93   \u001b[0m | \u001b[0m 5.285   \u001b[0m | \u001b[0m 4.106   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7824  \u001b[0m | \u001b[0m 0.04056 \u001b[0m | \u001b[0m 241.2   \u001b[0m | \u001b[0m 81.29   \u001b[0m | \u001b[0m 713.4   \u001b[0m | \u001b[0m 33.21   \u001b[0m | \u001b[0m 7.949   \u001b[0m | \u001b[0m 37.92   \u001b[0m | \u001b[0m 4.385   \u001b[0m | \u001b[0m 8.708   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7706  \u001b[0m | \u001b[0m 0.01253 \u001b[0m | \u001b[0m 118.9   \u001b[0m | \u001b[0m 22.5    \u001b[0m | \u001b[0m 995.4   \u001b[0m | \u001b[0m 76.78   \u001b[0m | \u001b[0m 18.52   \u001b[0m | \u001b[0m 129.7   \u001b[0m | \u001b[0m 9.854   \u001b[0m | \u001b[0m 4.336   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7889  \u001b[0m | \u001b[0m 0.05603 \u001b[0m | \u001b[0m 473.7   \u001b[0m | \u001b[0m 46.42   \u001b[0m | \u001b[0m 235.9   \u001b[0m | \u001b[0m 78.9    \u001b[0m | \u001b[0m 14.39   \u001b[0m | \u001b[0m 73.11   \u001b[0m | \u001b[0m 9.705   \u001b[0m | \u001b[0m 7.779   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7896  \u001b[0m | \u001b[0m 0.06801 \u001b[0m | \u001b[0m 499.9   \u001b[0m | \u001b[0m 30.5    \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 34.3    \u001b[0m | \u001b[0m 8.665   \u001b[0m | \u001b[0m 68.59   \u001b[0m | \u001b[0m 4.192   \u001b[0m | \u001b[0m 5.955   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7894  \u001b[0m | \u001b[0m 0.08508 \u001b[0m | \u001b[0m 221.8   \u001b[0m | \u001b[0m 85.11   \u001b[0m | \u001b[0m 58.09   \u001b[0m | \u001b[0m 52.94   \u001b[0m | \u001b[0m 24.27   \u001b[0m | \u001b[0m 62.65   \u001b[0m | \u001b[0m 0.3167  \u001b[0m | \u001b[0m 1.753   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7844  \u001b[0m | \u001b[0m 0.03757 \u001b[0m | \u001b[0m 259.0   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 421.3   \u001b[0m | \u001b[0m 15.16   \u001b[0m | \u001b[0m 57.46   \u001b[0m | \u001b[0m 113.6   \u001b[0m | \u001b[0m 5.151   \u001b[0m | \u001b[0m 5.544   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7842  \u001b[0m | \u001b[0m 0.03209 \u001b[0m | \u001b[0m 72.79   \u001b[0m | \u001b[0m 39.42   \u001b[0m | \u001b[0m 220.3   \u001b[0m | \u001b[0m 4.954   \u001b[0m | \u001b[0m 9.419   \u001b[0m | \u001b[0m 140.6   \u001b[0m | \u001b[0m 5.52    \u001b[0m | \u001b[0m 0.8598  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7734  \u001b[0m | \u001b[0m 0.01913 \u001b[0m | \u001b[0m 337.6   \u001b[0m | \u001b[0m 129.6   \u001b[0m | \u001b[0m 51.33   \u001b[0m | \u001b[0m 26.64   \u001b[0m | \u001b[0m 15.1    \u001b[0m | \u001b[0m 59.78   \u001b[0m | \u001b[0m 9.086   \u001b[0m | \u001b[0m 8.307   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7766  \u001b[0m | \u001b[0m 0.02447 \u001b[0m | \u001b[0m 252.7   \u001b[0m | \u001b[0m 65.65   \u001b[0m | \u001b[0m 835.0   \u001b[0m | \u001b[0m 73.85   \u001b[0m | \u001b[0m 79.71   \u001b[0m | \u001b[0m 62.49   \u001b[0m | \u001b[0m 3.707   \u001b[0m | \u001b[0m 8.072   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7801  \u001b[0m | \u001b[0m 0.03259 \u001b[0m | \u001b[0m 389.1   \u001b[0m | \u001b[0m 149.1   \u001b[0m | \u001b[0m 476.3   \u001b[0m | \u001b[0m 96.19   \u001b[0m | \u001b[0m 29.54   \u001b[0m | \u001b[0m 41.96   \u001b[0m | \u001b[0m 6.566   \u001b[0m | \u001b[0m 7.179   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.779   \u001b[0m | \u001b[0m 0.02499 \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 139.7   \u001b[0m | \u001b[0m 57.11   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 66.18   \u001b[0m | \u001b[0m 77.81   \u001b[0m | \u001b[0m 7.827   \u001b[0m | \u001b[0m 8.833   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7866  \u001b[0m | \u001b[0m 0.08862 \u001b[0m | \u001b[0m 238.8   \u001b[0m | \u001b[0m 144.4   \u001b[0m | \u001b[0m 592.0   \u001b[0m | \u001b[0m 78.43   \u001b[0m | \u001b[0m 86.3    \u001b[0m | \u001b[0m 110.2   \u001b[0m | \u001b[0m 2.624   \u001b[0m | \u001b[0m 4.194   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7829  \u001b[0m | \u001b[0m 0.03205 \u001b[0m | \u001b[0m 215.0   \u001b[0m | \u001b[0m 111.3   \u001b[0m | \u001b[0m 578.5   \u001b[0m | \u001b[0m 62.49   \u001b[0m | \u001b[0m 49.2    \u001b[0m | \u001b[0m 136.4   \u001b[0m | \u001b[0m 7.384   \u001b[0m | \u001b[0m 4.889   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.05161 \u001b[0m | \u001b[0m 449.6   \u001b[0m | \u001b[0m 98.79   \u001b[0m | \u001b[0m 666.3   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 15.52   \u001b[0m | \u001b[0m 142.7   \u001b[0m | \u001b[0m 8.009   \u001b[0m | \u001b[0m 0.4766  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7777  \u001b[0m | \u001b[0m 0.03652 \u001b[0m | \u001b[0m 313.0   \u001b[0m | \u001b[0m 32.55   \u001b[0m | \u001b[0m 306.4   \u001b[0m | \u001b[0m 93.83   \u001b[0m | \u001b[0m 83.06   \u001b[0m | \u001b[0m 22.63   \u001b[0m | \u001b[0m 5.433   \u001b[0m | \u001b[0m 1.973   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 0.06169 \u001b[0m | \u001b[0m 140.7   \u001b[0m | \u001b[0m 123.5   \u001b[0m | \u001b[0m 276.9   \u001b[0m | \u001b[0m 90.4    \u001b[0m | \u001b[0m 50.22   \u001b[0m | \u001b[0m 133.4   \u001b[0m | \u001b[0m 8.306   \u001b[0m | \u001b[0m 9.689   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7764  \u001b[0m | \u001b[0m 0.02245 \u001b[0m | \u001b[0m 389.7   \u001b[0m | \u001b[0m 84.59   \u001b[0m | \u001b[0m 734.2   \u001b[0m | \u001b[0m 24.48   \u001b[0m | \u001b[0m 9.523   \u001b[0m | \u001b[0m 58.08   \u001b[0m | \u001b[0m 3.819   \u001b[0m | \u001b[0m 6.108   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7875  \u001b[0m | \u001b[0m 0.06714 \u001b[0m | \u001b[0m 221.0   \u001b[0m | \u001b[0m 160.4   \u001b[0m | \u001b[0m 156.5   \u001b[0m | \u001b[0m 3.548   \u001b[0m | \u001b[0m 71.56   \u001b[0m | \u001b[0m 96.2    \u001b[0m | \u001b[0m 3.532   \u001b[0m | \u001b[0m 6.813   \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 0.7902  \u001b[0m | \u001b[95m 0.08662 \u001b[0m | \u001b[95m 501.6   \u001b[0m | \u001b[95m 62.95   \u001b[0m | \u001b[95m 772.8   \u001b[0m | \u001b[95m 22.93   \u001b[0m | \u001b[95m 18.34   \u001b[0m | \u001b[95m 77.84   \u001b[0m | \u001b[95m 6.109   \u001b[0m | \u001b[95m 5.778   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7889  \u001b[0m | \u001b[0m 0.0548  \u001b[0m | \u001b[0m 418.5   \u001b[0m | \u001b[0m 88.82   \u001b[0m | \u001b[0m 353.3   \u001b[0m | \u001b[0m 70.47   \u001b[0m | \u001b[0m 6.434   \u001b[0m | \u001b[0m 87.9    \u001b[0m | \u001b[0m 6.414   \u001b[0m | \u001b[0m 8.225   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.789   \u001b[0m | \u001b[0m 0.082   \u001b[0m | \u001b[0m 359.2   \u001b[0m | \u001b[0m 152.4   \u001b[0m | \u001b[0m 400.5   \u001b[0m | \u001b[0m 82.25   \u001b[0m | \u001b[0m 58.39   \u001b[0m | \u001b[0m 92.91   \u001b[0m | \u001b[0m 4.145   \u001b[0m | \u001b[0m 8.126   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7748  \u001b[0m | \u001b[0m 0.0478  \u001b[0m | \u001b[0m 69.34   \u001b[0m | \u001b[0m 166.8   \u001b[0m | \u001b[0m 985.0   \u001b[0m | \u001b[0m 9.121   \u001b[0m | \u001b[0m 69.02   \u001b[0m | \u001b[0m 10.39   \u001b[0m | \u001b[0m 8.001   \u001b[0m | \u001b[0m 2.266   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7667  \u001b[0m | \u001b[0m 0.01475 \u001b[0m | \u001b[0m 159.4   \u001b[0m | \u001b[0m 13.11   \u001b[0m | \u001b[0m 294.4   \u001b[0m | \u001b[0m 78.77   \u001b[0m | \u001b[0m 93.84   \u001b[0m | \u001b[0m 38.5    \u001b[0m | \u001b[0m 8.351   \u001b[0m | \u001b[0m 3.729   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7866  \u001b[0m | \u001b[0m 0.06549 \u001b[0m | \u001b[0m 309.3   \u001b[0m | \u001b[0m 113.4   \u001b[0m | \u001b[0m 930.3   \u001b[0m | \u001b[0m 26.75   \u001b[0m | \u001b[0m 65.23   \u001b[0m | \u001b[0m 29.63   \u001b[0m | \u001b[0m 5.136   \u001b[0m | \u001b[0m 8.479   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7699  \u001b[0m | \u001b[0m 0.01716 \u001b[0m | \u001b[0m 178.2   \u001b[0m | \u001b[0m 136.1   \u001b[0m | \u001b[0m 589.0   \u001b[0m | \u001b[0m 11.95   \u001b[0m | \u001b[0m 1.456   \u001b[0m | \u001b[0m 42.2    \u001b[0m | \u001b[0m 1.918   \u001b[0m | \u001b[0m 0.9178  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 0.06129 \u001b[0m | \u001b[0m 509.7   \u001b[0m | \u001b[0m 172.7   \u001b[0m | \u001b[0m 982.2   \u001b[0m | \u001b[0m 88.29   \u001b[0m | \u001b[0m 40.44   \u001b[0m | \u001b[0m 155.1   \u001b[0m | \u001b[0m 6.173   \u001b[0m | \u001b[0m 3.345   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7813  \u001b[0m | \u001b[0m 0.03376 \u001b[0m | \u001b[0m 286.5   \u001b[0m | \u001b[0m 49.63   \u001b[0m | \u001b[0m 263.0   \u001b[0m | \u001b[0m 33.3    \u001b[0m | \u001b[0m 28.37   \u001b[0m | \u001b[0m 48.93   \u001b[0m | \u001b[0m 0.4652  \u001b[0m | \u001b[0m 9.781   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7864  \u001b[0m | \u001b[0m 0.07377 \u001b[0m | \u001b[0m 509.4   \u001b[0m | \u001b[0m 158.6   \u001b[0m | \u001b[0m 166.8   \u001b[0m | \u001b[0m 58.8    \u001b[0m | \u001b[0m 84.6    \u001b[0m | \u001b[0m 155.5   \u001b[0m | \u001b[0m 2.607   \u001b[0m | \u001b[0m 5.466   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7737  \u001b[0m | \u001b[0m 0.01827 \u001b[0m | \u001b[0m 469.3   \u001b[0m | \u001b[0m 95.88   \u001b[0m | \u001b[0m 256.7   \u001b[0m | \u001b[0m 28.64   \u001b[0m | \u001b[0m 29.97   \u001b[0m | \u001b[0m 65.77   \u001b[0m | \u001b[0m 2.918   \u001b[0m | \u001b[0m 5.189   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7892  \u001b[0m | \u001b[0m 0.0942  \u001b[0m | \u001b[0m 464.8   \u001b[0m | \u001b[0m 47.69   \u001b[0m | \u001b[0m 982.2   \u001b[0m | \u001b[0m 0.1369  \u001b[0m | \u001b[0m 6.812   \u001b[0m | \u001b[0m 156.1   \u001b[0m | \u001b[0m 3.751   \u001b[0m | \u001b[0m 8.62    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7856  \u001b[0m | \u001b[0m 0.0478  \u001b[0m | \u001b[0m 504.9   \u001b[0m | \u001b[0m 10.27   \u001b[0m | \u001b[0m 997.8   \u001b[0m | \u001b[0m 80.92   \u001b[0m | \u001b[0m 23.18   \u001b[0m | \u001b[0m 66.28   \u001b[0m | \u001b[0m 7.143   \u001b[0m | \u001b[0m 0.9836  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7714  \u001b[0m | \u001b[0m 0.01867 \u001b[0m | \u001b[0m 488.7   \u001b[0m | \u001b[0m 44.7    \u001b[0m | \u001b[0m 739.7   \u001b[0m | \u001b[0m 10.95   \u001b[0m | \u001b[0m 31.39   \u001b[0m | \u001b[0m 43.2    \u001b[0m | \u001b[0m 3.584   \u001b[0m | \u001b[0m 9.881   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7724  \u001b[0m | \u001b[0m 0.02325 \u001b[0m | \u001b[0m 187.0   \u001b[0m | \u001b[0m 182.8   \u001b[0m | \u001b[0m 895.3   \u001b[0m | \u001b[0m 70.44   \u001b[0m | \u001b[0m 1.519   \u001b[0m | \u001b[0m 30.18   \u001b[0m | \u001b[0m 8.289   \u001b[0m | \u001b[0m 3.856   \u001b[0m |\n",
      "| \u001b[95m 35      \u001b[0m | \u001b[95m 0.7905  \u001b[0m | \u001b[95m 0.09347 \u001b[0m | \u001b[95m 232.7   \u001b[0m | \u001b[95m 86.76   \u001b[0m | \u001b[95m 62.75   \u001b[0m | \u001b[95m 53.65   \u001b[0m | \u001b[95m 31.98   \u001b[0m | \u001b[95m 65.01   \u001b[0m | \u001b[95m 7.555   \u001b[0m | \u001b[95m 2.551   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7835  \u001b[0m | \u001b[0m 0.03896 \u001b[0m | \u001b[0m 176.5   \u001b[0m | \u001b[0m 8.029   \u001b[0m | \u001b[0m 48.46   \u001b[0m | \u001b[0m 99.94   \u001b[0m | \u001b[0m 61.07   \u001b[0m | \u001b[0m 143.6   \u001b[0m | \u001b[0m 0.09635 \u001b[0m | \u001b[0m 9.191   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7874  \u001b[0m | \u001b[0m 0.04972 \u001b[0m | \u001b[0m 196.3   \u001b[0m | \u001b[0m 178.5   \u001b[0m | \u001b[0m 116.7   \u001b[0m | \u001b[0m 70.48   \u001b[0m | \u001b[0m 8.069   \u001b[0m | \u001b[0m 159.5   \u001b[0m | \u001b[0m 7.946   \u001b[0m | \u001b[0m 0.4226  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7812  \u001b[0m | \u001b[0m 0.09972 \u001b[0m | \u001b[0m 96.57   \u001b[0m | \u001b[0m 13.39   \u001b[0m | \u001b[0m 944.3   \u001b[0m | \u001b[0m 9.75    \u001b[0m | \u001b[0m 5.736   \u001b[0m | \u001b[0m 7.798   \u001b[0m | \u001b[0m 8.823   \u001b[0m | \u001b[0m 8.949   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7898  \u001b[0m | \u001b[0m 0.07668 \u001b[0m | \u001b[0m 484.4   \u001b[0m | \u001b[0m 180.8   \u001b[0m | \u001b[0m 990.2   \u001b[0m | \u001b[0m 2.207   \u001b[0m | \u001b[0m 20.51   \u001b[0m | \u001b[0m 52.6    \u001b[0m | \u001b[0m 5.115   \u001b[0m | \u001b[0m 2.239   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.785   \u001b[0m | \u001b[0m 0.089   \u001b[0m | \u001b[0m 92.1    \u001b[0m | \u001b[0m 162.0   \u001b[0m | \u001b[0m 922.9   \u001b[0m | \u001b[0m 2.151   \u001b[0m | \u001b[0m 97.14   \u001b[0m | \u001b[0m 157.6   \u001b[0m | \u001b[0m 9.992   \u001b[0m | \u001b[0m 0.344   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7901  \u001b[0m | \u001b[0m 0.07679 \u001b[0m | \u001b[0m 495.9   \u001b[0m | \u001b[0m 17.48   \u001b[0m | \u001b[0m 519.0   \u001b[0m | \u001b[0m 88.22   \u001b[0m | \u001b[0m 21.86   \u001b[0m | \u001b[0m 140.8   \u001b[0m | \u001b[0m 6.602   \u001b[0m | \u001b[0m 0.08499 \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7812  \u001b[0m | \u001b[0m 0.02479 \u001b[0m | \u001b[0m 507.7   \u001b[0m | \u001b[0m 180.5   \u001b[0m | \u001b[0m 357.4   \u001b[0m | \u001b[0m 97.75   \u001b[0m | \u001b[0m 16.21   \u001b[0m | \u001b[0m 149.5   \u001b[0m | \u001b[0m 5.167   \u001b[0m | \u001b[0m 7.501   \u001b[0m |\n",
      "=====================================================================================================================================\n",
      "Elapsed time=41365.80 sec.\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = { \n",
    "          'num_leaves': (7, 161), \n",
    "          'max_depth': (7, 189),\n",
    "          'learning_rate': (.01, .1),\n",
    "#           'n_estimators':(50, 1000),\n",
    "#           'subsample_for_bin':(50000, 1000000),\n",
    "#           'top_rate':(0.0 ,1.0),\n",
    "          'min_split_gain': (0.01, 100),\n",
    "#           'drop_rate': (0.0, 1.0),\n",
    "#           'max_drop': (28, 343),\n",
    "#           'skip_drop': (0.0, 1.0),\n",
    "          'min_child_weight': (0.01, 100),\n",
    "          'min_child_samples': (31, 999),\n",
    "#         subsample (float, optional (default=1.)) – Subsample ratio of the training instance.\n",
    "#         subsample_freq (int, optional (default=0)) – Frequence of subsample, <=0 means no enable.\n",
    "#         colsample_bytree (float, optional (default=1.)) – Subsample ratio of columns when constructing each tree.\n",
    "          'reg_alpha': (.00, 10.0), \n",
    "          'reg_lambda': (.00, 10.0), \n",
    "          'max_bin': (63, 511)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 21, n_iter = 21)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_list = bo.res\n",
    "len(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出參數檔案\n",
    "import json\n",
    "with open('./params_list_BayesOpt_20200218b_G3V3_le_lgbm.txt', 'w', encoding='utf-8') as fout:\n",
    "    for params in params_list:\n",
    "        json.dump(params, fout) \n",
    "        fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7905432997126065,\n",
       " 'params': {'learning_rate': 0.09346727590770554,\n",
       "  'max_bin': 232.70987523394012,\n",
       "  'max_depth': 86.7607272148453,\n",
       "  'min_child_samples': 62.75249786903486,\n",
       "  'min_child_weight': 53.647150443038534,\n",
       "  'min_split_gain': 31.983181764138173,\n",
       "  'num_leaves': 65.01255175905041,\n",
       "  'reg_alpha': 7.5550465322981575,\n",
       "  'reg_lambda': 2.550956592181958}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.7896981134056991,\n",
       "  'params': {'learning_rate': 0.08243778949235828,\n",
       "   'max_bin': 466.12314474437005,\n",
       "   'max_depth': 168.79134784984964,\n",
       "   'min_child_samples': 263.96762383972276,\n",
       "   'min_child_weight': 59.34255443732015,\n",
       "   'min_split_gain': 8.029242242599846,\n",
       "   'num_leaves': 54.931066990669535,\n",
       "   'reg_alpha': 5.285397017230134,\n",
       "   'reg_lambda': 4.106292783360783}},\n",
       " {'target': 0.78235826457147,\n",
       "  'params': {'learning_rate': 0.04055691339842515,\n",
       "   'max_bin': 241.1517502875061,\n",
       "   'max_depth': 81.2897594567087,\n",
       "   'min_child_samples': 713.3819465276504,\n",
       "   'min_child_weight': 33.2075779542688,\n",
       "   'min_split_gain': 7.948561102844481,\n",
       "   'num_leaves': 37.92164255119664,\n",
       "   'reg_alpha': 4.385411691553306,\n",
       "   'reg_lambda': 8.707835599803387}},\n",
       " {'target': 0.7706340691698259,\n",
       "  'params': {'learning_rate': 0.01253016775134765,\n",
       "   'max_bin': 118.85933536248105,\n",
       "   'max_depth': 22.501291907707994,\n",
       "   'min_child_samples': 995.3502441006713,\n",
       "   'min_child_weight': 76.77580672125455,\n",
       "   'min_split_gain': 18.522946688713724,\n",
       "   'num_leaves': 129.73482470310512,\n",
       "   'reg_alpha': 9.85399178457827,\n",
       "   'reg_lambda': 4.3358400190188195}},\n",
       " {'target': 0.7888890572731235,\n",
       "  'params': {'learning_rate': 0.05603429772994559,\n",
       "   'max_bin': 473.67554865379327,\n",
       "   'max_depth': 46.42079044327469,\n",
       "   'min_child_samples': 235.91039227275263,\n",
       "   'min_child_weight': 78.89558441966717,\n",
       "   'min_split_gain': 14.38970902691071,\n",
       "   'num_leaves': 73.11058772194113,\n",
       "   'reg_alpha': 9.705205092849987,\n",
       "   'reg_lambda': 7.77942831677929}},\n",
       " {'target': 0.7896439234165987,\n",
       "  'params': {'learning_rate': 0.06801376893482002,\n",
       "   'max_bin': 499.8692040994556,\n",
       "   'max_depth': 30.496764206808617,\n",
       "   'min_child_samples': 362.5915183698172,\n",
       "   'min_child_weight': 34.29661707206705,\n",
       "   'min_split_gain': 8.66467148793121,\n",
       "   'num_leaves': 68.59329833216,\n",
       "   'reg_alpha': 4.192054363480233,\n",
       "   'reg_lambda': 5.954554194148657}},\n",
       " {'target': 0.789445519241726,\n",
       "  'params': {'learning_rate': 0.08508226859531198,\n",
       "   'max_bin': 221.83397392906198,\n",
       "   'max_depth': 85.11468298472245,\n",
       "   'min_child_samples': 58.088555762523924,\n",
       "   'min_child_weight': 52.935283850680754,\n",
       "   'min_split_gain': 24.26635522908847,\n",
       "   'num_leaves': 62.648047214729154,\n",
       "   'reg_alpha': 0.31665782698445666,\n",
       "   'reg_lambda': 1.7529978571618232}},\n",
       " {'target': 0.7844134388032331,\n",
       "  'params': {'learning_rate': 0.03756502764794959,\n",
       "   'max_bin': 258.97532833407047,\n",
       "   'max_depth': 12.180901357403382,\n",
       "   'min_child_samples': 421.3273554778005,\n",
       "   'min_child_weight': 15.155789921832858,\n",
       "   'min_split_gain': 57.4642262223263,\n",
       "   'num_leaves': 113.57533715912038,\n",
       "   'reg_alpha': 5.151362532475925,\n",
       "   'reg_lambda': 5.544392885122878}},\n",
       " {'target': 0.7841836513219729,\n",
       "  'params': {'learning_rate': 0.0320933282192563,\n",
       "   'max_bin': 72.78748089083055,\n",
       "   'max_depth': 39.417261975216746,\n",
       "   'min_child_samples': 220.2910271833264,\n",
       "   'min_child_weight': 4.953898864901229,\n",
       "   'min_split_gain': 9.418566321464244,\n",
       "   'num_leaves': 140.55240958225068,\n",
       "   'reg_alpha': 5.519738643086249,\n",
       "   'reg_lambda': 0.8597687578692337}},\n",
       " {'target': 0.7733913332710478,\n",
       "  'params': {'learning_rate': 0.019130310800929844,\n",
       "   'max_bin': 337.59337123889253,\n",
       "   'max_depth': 129.57193133370626,\n",
       "   'min_child_samples': 51.331916617874505,\n",
       "   'min_child_weight': 26.637081037797245,\n",
       "   'min_split_gain': 15.0965270417501,\n",
       "   'num_leaves': 59.78311062754272,\n",
       "   'reg_alpha': 9.085513981522844,\n",
       "   'reg_lambda': 8.306806512937984}},\n",
       " {'target': 0.7765780220569906,\n",
       "  'params': {'learning_rate': 0.02446760266384515,\n",
       "   'max_bin': 252.70274630781176,\n",
       "   'max_depth': 65.65117263495283,\n",
       "   'min_child_samples': 835.0113791234484,\n",
       "   'min_child_weight': 73.85355748011584,\n",
       "   'min_split_gain': 79.70671717120305,\n",
       "   'num_leaves': 62.48569315750689,\n",
       "   'reg_alpha': 3.7066354451009986,\n",
       "   'reg_lambda': 8.07170534349473}},\n",
       " {'target': 0.7800552044269276,\n",
       "  'params': {'learning_rate': 0.032590821708028836,\n",
       "   'max_bin': 389.10598686153276,\n",
       "   'max_depth': 149.1476714899225,\n",
       "   'min_child_samples': 476.31891270152096,\n",
       "   'min_child_weight': 96.19262057736897,\n",
       "   'min_split_gain': 29.538287199018374,\n",
       "   'num_leaves': 41.95631815697975,\n",
       "   'reg_alpha': 6.566272634291332,\n",
       "   'reg_lambda': 7.179289497059591}},\n",
       " {'target': 0.7789922887549182,\n",
       "  'params': {'learning_rate': 0.024991204590218856,\n",
       "   'max_bin': 139.97760508069987,\n",
       "   'max_depth': 139.693949825227,\n",
       "   'min_child_samples': 57.10672044840808,\n",
       "   'min_child_weight': 50.00134693866465,\n",
       "   'min_split_gain': 66.18494353655414,\n",
       "   'num_leaves': 77.80914853208105,\n",
       "   'reg_alpha': 7.827086708482755,\n",
       "   'reg_lambda': 8.83270724292399}},\n",
       " {'target': 0.7866090534664522,\n",
       "  'params': {'learning_rate': 0.08861683497752137,\n",
       "   'max_bin': 238.84680109523129,\n",
       "   'max_depth': 144.4091099118951,\n",
       "   'min_child_samples': 592.0420432919072,\n",
       "   'min_child_weight': 78.4323200823036,\n",
       "   'min_split_gain': 86.29950422871048,\n",
       "   'num_leaves': 110.18135602162265,\n",
       "   'reg_alpha': 2.6244489791378545,\n",
       "   'reg_lambda': 4.193502767165907}},\n",
       " {'target': 0.7829151055827219,\n",
       "  'params': {'learning_rate': 0.032047234388992,\n",
       "   'max_bin': 214.9771008493462,\n",
       "   'max_depth': 111.25388638857832,\n",
       "   'min_child_samples': 578.5341427903397,\n",
       "   'min_child_weight': 62.48776000972299,\n",
       "   'min_split_gain': 49.19535848048109,\n",
       "   'num_leaves': 136.3943650564522,\n",
       "   'reg_alpha': 7.384469772845743,\n",
       "   'reg_lambda': 4.889460975841887}},\n",
       " {'target': 0.7883930078629477,\n",
       "  'params': {'learning_rate': 0.0516091789997985,\n",
       "   'max_bin': 449.5852038055168,\n",
       "   'max_depth': 98.79372439217987,\n",
       "   'min_child_samples': 666.2875181926267,\n",
       "   'min_child_weight': 18.616713306498756,\n",
       "   'min_split_gain': 15.522298009686248,\n",
       "   'num_leaves': 142.68681189439258,\n",
       "   'reg_alpha': 8.008597512693756,\n",
       "   'reg_lambda': 0.47663074198084465}},\n",
       " {'target': 0.7776664368969974,\n",
       "  'params': {'learning_rate': 0.036522009728016024,\n",
       "   'max_bin': 312.9973225984181,\n",
       "   'max_depth': 32.547598480222995,\n",
       "   'min_child_samples': 306.3861053565561,\n",
       "   'min_child_weight': 93.82865525956821,\n",
       "   'min_split_gain': 83.06435447757228,\n",
       "   'num_leaves': 22.630728010833984,\n",
       "   'reg_alpha': 5.432850264878307,\n",
       "   'reg_lambda': 1.9726032071997934}},\n",
       " {'target': 0.7882096271717265,\n",
       "  'params': {'learning_rate': 0.06169194869603072,\n",
       "   'max_bin': 140.66572557238038,\n",
       "   'max_depth': 123.46027159405044,\n",
       "   'min_child_samples': 276.93955643791173,\n",
       "   'min_child_weight': 90.40158446474567,\n",
       "   'min_split_gain': 50.219229041359704,\n",
       "   'num_leaves': 133.35562720809898,\n",
       "   'reg_alpha': 8.306141532106011,\n",
       "   'reg_lambda': 9.688713098516718}},\n",
       " {'target': 0.7763521499722996,\n",
       "  'params': {'learning_rate': 0.02244769031066586,\n",
       "   'max_bin': 389.7092229680288,\n",
       "   'max_depth': 84.59484994300914,\n",
       "   'min_child_samples': 734.1866280369646,\n",
       "   'min_child_weight': 24.475296290291755,\n",
       "   'min_split_gain': 9.523026041939284,\n",
       "   'num_leaves': 58.083796295179965,\n",
       "   'reg_alpha': 3.818904010607893,\n",
       "   'reg_lambda': 6.107638776209736}},\n",
       " {'target': 0.7874726542637498,\n",
       "  'params': {'learning_rate': 0.06713987875532151,\n",
       "   'max_bin': 220.99655177866754,\n",
       "   'max_depth': 160.44330824313556,\n",
       "   'min_child_samples': 156.49966607479075,\n",
       "   'min_child_weight': 3.548272421889302,\n",
       "   'min_split_gain': 71.56102424227544,\n",
       "   'num_leaves': 96.2025438769043,\n",
       "   'reg_alpha': 3.5324730116313354,\n",
       "   'reg_lambda': 6.812954287966447}},\n",
       " {'target': 0.7901642737355099,\n",
       "  'params': {'learning_rate': 0.08661652062152753,\n",
       "   'max_bin': 501.5621837157406,\n",
       "   'max_depth': 62.953845761301494,\n",
       "   'min_child_samples': 772.7779165181825,\n",
       "   'min_child_weight': 22.929605988437682,\n",
       "   'min_split_gain': 18.34196792444013,\n",
       "   'num_leaves': 77.84272652383783,\n",
       "   'reg_alpha': 6.109027362545286,\n",
       "   'reg_lambda': 5.777795318140568}},\n",
       " {'target': 0.7888677867106209,\n",
       "  'params': {'learning_rate': 0.05480170644916419,\n",
       "   'max_bin': 418.53095268709865,\n",
       "   'max_depth': 88.82426652507334,\n",
       "   'min_child_samples': 353.33004807360027,\n",
       "   'min_child_weight': 70.46905533752127,\n",
       "   'min_split_gain': 6.4340030152365175,\n",
       "   'num_leaves': 87.89707919519086,\n",
       "   'reg_alpha': 6.414154644548625,\n",
       "   'reg_lambda': 8.225387787957319}},\n",
       " {'target': 0.7890181989561948,\n",
       "  'params': {'learning_rate': 0.08199674970197274,\n",
       "   'max_bin': 359.2458148307957,\n",
       "   'max_depth': 152.44964995240395,\n",
       "   'min_child_samples': 400.46161320118046,\n",
       "   'min_child_weight': 82.25365940922624,\n",
       "   'min_split_gain': 58.39237896802732,\n",
       "   'num_leaves': 92.91427713000306,\n",
       "   'reg_alpha': 4.145007732115489,\n",
       "   'reg_lambda': 8.125771367158176}},\n",
       " {'target': 0.7747786250924708,\n",
       "  'params': {'learning_rate': 0.047798521143861274,\n",
       "   'max_bin': 69.34232455896945,\n",
       "   'max_depth': 166.8296551682919,\n",
       "   'min_child_samples': 985.0082758483637,\n",
       "   'min_child_weight': 9.121057421723672,\n",
       "   'min_split_gain': 69.01512883419737,\n",
       "   'num_leaves': 10.39354339169206,\n",
       "   'reg_alpha': 8.001483009040577,\n",
       "   'reg_lambda': 2.2660839277778133}},\n",
       " {'target': 0.76667608644649,\n",
       "  'params': {'learning_rate': 0.014747761211447719,\n",
       "   'max_bin': 159.37359946820843,\n",
       "   'max_depth': 13.107694308213405,\n",
       "   'min_child_samples': 294.36666584828123,\n",
       "   'min_child_weight': 78.76907265724111,\n",
       "   'min_split_gain': 93.83676423556773,\n",
       "   'num_leaves': 38.49599551419973,\n",
       "   'reg_alpha': 8.350616444840197,\n",
       "   'reg_lambda': 3.728788020282603}},\n",
       " {'target': 0.7865958334278268,\n",
       "  'params': {'learning_rate': 0.06548668789294225,\n",
       "   'max_bin': 309.33149755286394,\n",
       "   'max_depth': 113.36308361459429,\n",
       "   'min_child_samples': 930.320731618827,\n",
       "   'min_child_weight': 26.752438946004332,\n",
       "   'min_split_gain': 65.23085832178297,\n",
       "   'num_leaves': 29.63444549231884,\n",
       "   'reg_alpha': 5.135812730364016,\n",
       "   'reg_lambda': 8.478848089634992}},\n",
       " {'target': 0.7698836788645512,\n",
       "  'params': {'learning_rate': 0.01716401520178832,\n",
       "   'max_bin': 178.24389967997533,\n",
       "   'max_depth': 136.09214246875862,\n",
       "   'min_child_samples': 589.0080818766542,\n",
       "   'min_child_weight': 11.949243748684651,\n",
       "   'min_split_gain': 1.4559411214961173,\n",
       "   'num_leaves': 42.204199250526656,\n",
       "   'reg_alpha': 1.9182950988447611,\n",
       "   'reg_lambda': 0.917754074063083}},\n",
       " {'target': 0.788232913072646,\n",
       "  'params': {'learning_rate': 0.06128983661270296,\n",
       "   'max_bin': 509.65847608837544,\n",
       "   'max_depth': 172.69720275750817,\n",
       "   'min_child_samples': 982.1639030514433,\n",
       "   'min_child_weight': 88.28938232106714,\n",
       "   'min_split_gain': 40.44003737680404,\n",
       "   'num_leaves': 155.1188134062935,\n",
       "   'reg_alpha': 6.173062116462102,\n",
       "   'reg_lambda': 3.3447211070102565}},\n",
       " {'target': 0.7813435685393433,\n",
       "  'params': {'learning_rate': 0.03375614419640076,\n",
       "   'max_bin': 286.4939841382815,\n",
       "   'max_depth': 49.629645648837496,\n",
       "   'min_child_samples': 263.04262803956306,\n",
       "   'min_child_weight': 33.30300634766924,\n",
       "   'min_split_gain': 28.36622236409302,\n",
       "   'num_leaves': 48.929243191416866,\n",
       "   'reg_alpha': 0.4651580910286923,\n",
       "   'reg_lambda': 9.781310073757027}},\n",
       " {'target': 0.7864062058002517,\n",
       "  'params': {'learning_rate': 0.07376669913554555,\n",
       "   'max_bin': 509.3746364902503,\n",
       "   'max_depth': 158.59425627264622,\n",
       "   'min_child_samples': 166.77869028686587,\n",
       "   'min_child_weight': 58.800875977745534,\n",
       "   'min_split_gain': 84.59807883630823,\n",
       "   'num_leaves': 155.51441781626016,\n",
       "   'reg_alpha': 2.607431971394046,\n",
       "   'reg_lambda': 5.466134861289128}},\n",
       " {'target': 0.7736943365449431,\n",
       "  'params': {'learning_rate': 0.018268026460704367,\n",
       "   'max_bin': 469.347056215489,\n",
       "   'max_depth': 95.88201050953202,\n",
       "   'min_child_samples': 256.7216427389208,\n",
       "   'min_child_weight': 28.63825907265143,\n",
       "   'min_split_gain': 29.966851146660126,\n",
       "   'num_leaves': 65.7711073933948,\n",
       "   'reg_alpha': 2.9183623801619007,\n",
       "   'reg_lambda': 5.188654469467734}},\n",
       " {'target': 0.7892050696897341,\n",
       "  'params': {'learning_rate': 0.09420009127453434,\n",
       "   'max_bin': 464.8223730325883,\n",
       "   'max_depth': 47.691319325931644,\n",
       "   'min_child_samples': 982.1981011542,\n",
       "   'min_child_weight': 0.13685790115677804,\n",
       "   'min_split_gain': 6.811968641450534,\n",
       "   'num_leaves': 156.08594262241084,\n",
       "   'reg_alpha': 3.7505759110045767,\n",
       "   'reg_lambda': 8.619902634578098}},\n",
       " {'target': 0.7855870131267528,\n",
       "  'params': {'learning_rate': 0.04780020803768488,\n",
       "   'max_bin': 504.86118209898825,\n",
       "   'max_depth': 10.26602268364276,\n",
       "   'min_child_samples': 997.7786339873837,\n",
       "   'min_child_weight': 80.92315275491674,\n",
       "   'min_split_gain': 23.180069550387675,\n",
       "   'num_leaves': 66.27882728207004,\n",
       "   'reg_alpha': 7.142806394784432,\n",
       "   'reg_lambda': 0.9835981418529072}},\n",
       " {'target': 0.7713773715200564,\n",
       "  'params': {'learning_rate': 0.01867182102978814,\n",
       "   'max_bin': 488.6762490195754,\n",
       "   'max_depth': 44.69942353121637,\n",
       "   'min_child_samples': 739.7237093974782,\n",
       "   'min_child_weight': 10.95139658011696,\n",
       "   'min_split_gain': 31.389304718239085,\n",
       "   'num_leaves': 43.20372831176307,\n",
       "   'reg_alpha': 3.5838732465812564,\n",
       "   'reg_lambda': 9.881374347856337}},\n",
       " {'target': 0.7723534600633931,\n",
       "  'params': {'learning_rate': 0.023254064716952516,\n",
       "   'max_bin': 187.01474701932648,\n",
       "   'max_depth': 182.786834335964,\n",
       "   'min_child_samples': 895.3031569905206,\n",
       "   'min_child_weight': 70.43737735690246,\n",
       "   'min_split_gain': 1.519125421399757,\n",
       "   'num_leaves': 30.181172037766846,\n",
       "   'reg_alpha': 8.288856290236957,\n",
       "   'reg_lambda': 3.85647671928386}},\n",
       " {'target': 0.7905432997126065,\n",
       "  'params': {'learning_rate': 0.09346727590770554,\n",
       "   'max_bin': 232.70987523394012,\n",
       "   'max_depth': 86.7607272148453,\n",
       "   'min_child_samples': 62.75249786903486,\n",
       "   'min_child_weight': 53.647150443038534,\n",
       "   'min_split_gain': 31.983181764138173,\n",
       "   'num_leaves': 65.01255175905041,\n",
       "   'reg_alpha': 7.5550465322981575,\n",
       "   'reg_lambda': 2.550956592181958}},\n",
       " {'target': 0.783540037615993,\n",
       "  'params': {'learning_rate': 0.03895848079976717,\n",
       "   'max_bin': 176.45891673032824,\n",
       "   'max_depth': 8.028719926561166,\n",
       "   'min_child_samples': 48.45903418217101,\n",
       "   'min_child_weight': 99.94451233726244,\n",
       "   'min_split_gain': 61.07338556988565,\n",
       "   'num_leaves': 143.59884181462505,\n",
       "   'reg_alpha': 0.09634763577094807,\n",
       "   'reg_lambda': 9.191028752032558}},\n",
       " {'target': 0.7874373225014343,\n",
       "  'params': {'learning_rate': 0.04971977781313909,\n",
       "   'max_bin': 196.29919290933734,\n",
       "   'max_depth': 178.48017024722876,\n",
       "   'min_child_samples': 116.69217960834867,\n",
       "   'min_child_weight': 70.47515690713523,\n",
       "   'min_split_gain': 8.069264712756821,\n",
       "   'num_leaves': 159.5111554492311,\n",
       "   'reg_alpha': 7.94590660901322,\n",
       "   'reg_lambda': 0.42259020192521257}},\n",
       " {'target': 0.7812176572686247,\n",
       "  'params': {'learning_rate': 0.09972009443091062,\n",
       "   'max_bin': 96.56503375714755,\n",
       "   'max_depth': 13.38755675540896,\n",
       "   'min_child_samples': 944.3117935663414,\n",
       "   'min_child_weight': 9.750220971841394,\n",
       "   'min_split_gain': 5.735547367221146,\n",
       "   'num_leaves': 7.798085133105679,\n",
       "   'reg_alpha': 8.823464762631858,\n",
       "   'reg_lambda': 8.949324948766254}},\n",
       " {'target': 0.7898013272890849,\n",
       "  'params': {'learning_rate': 0.07668075054368129,\n",
       "   'max_bin': 484.36186466380684,\n",
       "   'max_depth': 180.77136332207456,\n",
       "   'min_child_samples': 990.1566852500029,\n",
       "   'min_child_weight': 2.206868715594755,\n",
       "   'min_split_gain': 20.51387555777717,\n",
       "   'num_leaves': 52.598393793898055,\n",
       "   'reg_alpha': 5.114835874688399,\n",
       "   'reg_lambda': 2.2394223944480807}},\n",
       " {'target': 0.7849663135464022,\n",
       "  'params': {'learning_rate': 0.08899885212213146,\n",
       "   'max_bin': 92.0985032220467,\n",
       "   'max_depth': 161.95724150856728,\n",
       "   'min_child_samples': 922.8979517965032,\n",
       "   'min_child_weight': 2.1507442266246968,\n",
       "   'min_split_gain': 97.14211011601438,\n",
       "   'num_leaves': 157.59457296225253,\n",
       "   'reg_alpha': 9.992496099550998,\n",
       "   'reg_lambda': 0.3440467605131492}},\n",
       " {'target': 0.7900792464894326,\n",
       "  'params': {'learning_rate': 0.07678770397884553,\n",
       "   'max_bin': 495.8982636328977,\n",
       "   'max_depth': 17.48052470476768,\n",
       "   'min_child_samples': 518.9871624032637,\n",
       "   'min_child_weight': 88.2180148399898,\n",
       "   'min_split_gain': 21.86248718432984,\n",
       "   'num_leaves': 140.81961698466142,\n",
       "   'reg_alpha': 6.601888731837718,\n",
       "   'reg_lambda': 0.08498607943204006}},\n",
       " {'target': 0.7811648912544096,\n",
       "  'params': {'learning_rate': 0.02479030973235062,\n",
       "   'max_bin': 507.6952886125076,\n",
       "   'max_depth': 180.54115636455973,\n",
       "   'min_child_samples': 357.3603069189505,\n",
       "   'min_child_weight': 97.75408999176129,\n",
       "   'min_split_gain': 16.205619025974812,\n",
       "   'num_leaves': 149.49797155063447,\n",
       "   'reg_alpha': 5.167204245059326,\n",
       "   'reg_lambda': 7.500587642897157}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7905432997126065,\n",
       " 'params': {'learning_rate': 0.09346727590770554,\n",
       "  'max_bin': 232.70987523394012,\n",
       "  'max_depth': 86.7607272148453,\n",
       "  'min_child_samples': 62.75249786903486,\n",
       "  'min_child_weight': 53.647150443038534,\n",
       "  'min_split_gain': 31.983181764138173,\n",
       "  'num_leaves': 65.01255175905041,\n",
       "  'reg_alpha': 7.5550465322981575,\n",
       "  'reg_lambda': 2.550956592181958}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_list[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7901642737355099,\n",
       " 'params': {'learning_rate': 0.08661652062152753,\n",
       "  'max_bin': 501.5621837157406,\n",
       "  'max_depth': 62.953845761301494,\n",
       "  'min_child_samples': 772.7779165181825,\n",
       "  'min_child_weight': 22.929605988437682,\n",
       "  'min_split_gain': 18.34196792444013,\n",
       "  'num_leaves': 77.84272652383783,\n",
       "  'reg_alpha': 6.109027362545286,\n",
       "  'reg_lambda': 5.777795318140568}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_list[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_list[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for looping\n",
    "# params_list = [bo.res[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取參數檔案\n",
    "with open('../../../BDSE12-Group3/datasets/homecdt_ss_output/params_list_BayesOpt_20200210a.txt', 'r', encoding='utf-8') as f:\n",
    "    params_list_read = list(map(json.loads,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_read[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(params_list_read[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ========The end of BayesianOptimization========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface connecting fteng & model parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign df to final_df for follow-up modeling\n",
    "final_df = df\n",
    "\n",
    "# Apply the following gc if memory is running slow\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in final_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling part. If using a ready dataset, please start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the saved dtypes Series\n",
    "final_df_dtypes = \\\n",
    "pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_G3V3_le_recip_20200217a_dtypes_series.csv'\\\n",
    "            , header=None, index_col=0, squeeze=True)\n",
    "del final_df_dtypes.index.name\n",
    "final_df_dtypes = final_df_dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = \\\n",
    "pd.read_csv('../../../BDSE12-Group3/datasets/homecdt_ss_output/ss_fteng_G3V3_le_recip_20200217a.csv'\\\n",
    "           , dtype= final_df_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in final_df.columns]\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following is based on 'bear_Final_model' released 2020/01/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forked from excellent kernel : https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features\n",
    "# From Kaggler : https://www.kaggle.com/jsaguiar\n",
    "# Just added a few features so I thought I had to make release it as well...\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48744 float64\n"
     ]
    }
   ],
   "source": [
    "print(final_df['TARGET'].isna().sum(), \n",
    "      final_df['TARGET'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 356255, 0.1368)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['TARGET'].isnull().sum(), \\\n",
    "final_df['TARGET'].size, \\\n",
    "(final_df['TARGET'].isnull().sum()/final_df['TARGET'].size).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00000000    282686\n",
       "1.00000000     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.387150050352467"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'scale_pos_weight'\n",
    "282686/24825 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取參數檔案\n",
    "import json\n",
    "with open('./params_list_BayesOpt_20200218b_G3V3_le_lgbm.txt', 'r', encoding='utf-8') as f:\n",
    "    params_list_read = list(map(json.loads,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7905432997126065,\n",
       " 'params': {'learning_rate': 0.09346727590770554,\n",
       "  'max_bin': 232.70987523394012,\n",
       "  'max_depth': 86.7607272148453,\n",
       "  'min_child_samples': 62.75249786903486,\n",
       "  'min_child_weight': 53.647150443038534,\n",
       "  'min_split_gain': 31.983181764138173,\n",
       "  'num_leaves': 65.01255175905041,\n",
       "  'reg_alpha': 7.5550465322981575,\n",
       "  'reg_lambda': 2.550956592181958}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params_list_read\n",
    "params_list_read[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7901642737355099,\n",
       " 'params': {'learning_rate': 0.08661652062152753,\n",
       "  'max_bin': 501.5621837157406,\n",
       "  'max_depth': 62.953845761301494,\n",
       "  'min_child_samples': 772.7779165181825,\n",
       "  'min_child_weight': 22.929605988437682,\n",
       "  'min_split_gain': 18.34196792444013,\n",
       "  'num_leaves': 77.84272652383783,\n",
       "  'reg_alpha': 6.109027362545286,\n",
       "  'reg_lambda': 5.777795318140568}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params_list_read\n",
    "params_list_read[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "def kfold_lightgbm(df, num_folds = 5, stratified = True, debug= False, boosting_type= 'goss', epoch=20000, early_stop=200):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM goss. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=924)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=924)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                             label=train_df['TARGET'].iloc[train_idx], \n",
    "                             free_raw_data=False, silent=True)\n",
    "        dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                             label=train_df['TARGET'].iloc[valid_idx], \n",
    "                             free_raw_data=False, silent=True)\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "\n",
    "# params_list_BayesOpt_20200218b_G3V3_le_lgbm.txt[34]\n",
    "# {'target': 0.7905432997126065,\n",
    "#  'params': {'learning_rate': 0.09346727590770554,\n",
    "#   'max_bin': 232.70987523394012,\n",
    "#   'max_depth': 86.7607272148453,\n",
    "#   'min_child_samples': 62.75249786903486,\n",
    "#   'min_child_weight': 53.647150443038534,\n",
    "#   'min_split_gain': 31.983181764138173,\n",
    "#   'num_leaves': 65.01255175905041,\n",
    "#   'reg_alpha': 7.5550465322981575,\n",
    "#   'reg_lambda': 2.550956592181958}}\n",
    "\n",
    "        params = {\n",
    "            'learning_rate': 0.09346727590770554,\n",
    "            'max_bin': 233,\n",
    "            'max_depth': 57,\n",
    "            'min_child_samples': 63, \n",
    "            'min_child_weight': 53.647150443038534,\n",
    "            'min_split_gain': 31.983181764138173,            \n",
    "            'num_leaves': 65,\n",
    "            'reg_alpha': 7.5550465322981575,\n",
    "            'reg_lambda': 2.550956592181958,\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': boosting_type,\n",
    "            'nthread': 4,\n",
    "            'scale_pos_weight': 11.387150050352467,\n",
    "            'seed': 924,\n",
    "            'verbose': 2000,\n",
    "            'metric': 'auc',\n",
    "\n",
    "#             'subsample': 0.9556663511637553,\n",
    "#             'tree_learner': 'voting',\n",
    "#             'colsample_bytree': 0.9497036,\n",
    "#             'subsample_freq': 0,          \n",
    "#             'histogram_pool_size': 20480\n",
    "#             'device' : 'gpu',\n",
    "#             'gpu_platform_id': 0,\n",
    "#             'gpu_device_id':0\n",
    "        }\n",
    "        \n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=epoch,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            early_stopping_rounds=early_stop,\n",
    "            verbose_eval=2000\n",
    "        )\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "        sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(dvalid.label, oof_preds[valid_idx])))\n",
    "        del clf, dtrain, dvalid\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        sub_df = test_df[['SK_ID_CURR']].copy()\n",
    "        sub_df['TARGET'] = sub_preds\n",
    "        sub_df[['SK_ID_CURR', 'TARGET']].to_csv('./homecdt_submission_LGBM.csv', index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout\n",
    "    plt.savefig('./lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：goss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM goss. Train shape: (307511, 2086), test shape: (48744, 2086)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's auc: 0.883028\tvalid_1's auc: 0.783282\n",
      "Fold  1 AUC : 0.783282\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.871411\tvalid_1's auc: 0.789138\n",
      "Fold  2 AUC : 0.789138\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\ttraining's auc: 0.881318\tvalid_1's auc: 0.786246\n",
      "Fold  3 AUC : 0.786246\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's auc: 0.874788\tvalid_1's auc: 0.788298\n",
      "Fold  4 AUC : 0.788298\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[325]\ttraining's auc: 0.885328\tvalid_1's auc: 0.79506\n",
      "Fold  5 AUC : 0.795060\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\ttraining's auc: 0.88613\tvalid_1's auc: 0.788818\n",
      "Fold  6 AUC : 0.788818\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's auc: 0.888474\tvalid_1's auc: 0.800174\n",
      "Fold  7 AUC : 0.800174\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttraining's auc: 0.885022\tvalid_1's auc: 0.794215\n",
      "Fold  8 AUC : 0.794215\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "kfold_lightgbm(final_df,10)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "kfold_lightgbm(final_df,10)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_time = time.time()\n",
    "# kfold_lightgbm(final_df, 10, boosting_type= 'gbdt')\n",
    "# print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_time = time.time()\n",
    "# kfold_lightgbm(final_df,10, boosting_type= 'dart')\n",
    "# print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting_type：rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_time = time.time()\n",
    "# kfold_lightgbm(final_df,10,boosting_type= 'rf')\n",
    "# print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_xgb(df, num_folds, stratified = True, debug= False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting XGBoost. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1054)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1054)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        #if n_fold == 0: # REmove for full K-fold run\n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf = XGBClassifier(learning_rate =0.01, \n",
    "                            n_estimators=5000, \n",
    "                            max_depth=4, \n",
    "                            min_child_weight=5,\n",
    "#                             tree_method='gpu_hist',\n",
    "                            subsample=0.8, \n",
    "                            colsample_bytree=0.8, \n",
    "                            objective= 'binary:logistic',\n",
    "                            nthread=4,\n",
    "                            scale_pos_weight=2.5,\n",
    "                            seed=28,\n",
    "                            reg_lambda = 1.2)\n",
    "        \n",
    "#         clf = pickle.load(open('test.pickle','rb'))\n",
    "        \n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 1000, early_stopping_rounds= 200)\n",
    "        \n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        \n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats])[:, 1] # / folds.n_splits # - Uncomment for K-fold \n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "        np.save(\"xgb_oof_preds_1\", oof_preds)\n",
    "        np.save(\"xgb_sub_preds_1\", sub_preds)\n",
    "        \n",
    "        cuda.select_device(0)\n",
    "        cuda.close()\n",
    "        \n",
    "    \n",
    "    clf = pickle.load(open('test.pickle','rb'))\n",
    "    # print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv('submission_XGBoost_GPU.csv', index= False)\n",
    "    #display_importances(feature_importance_df)\n",
    "    #return feature_importance_df\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('XGBoost Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('xgb_importances02.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "kfold_xgb(final_df, 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below not executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the 'TARGET' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanceFactor = ((appl_all_processed_df['TARGET'].value_counts()[0])/(appl_all_processed_df['TARGET'].value_counts()[1])).round(0).astype(int)\n",
    "balanceFactor\n",
    "# appl_all_processed_df['TARGET'].value_counts()[0]\n",
    "# appl_all_processed_df['TARGET'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df = appl_all_processed_df[appl_all_processed_df['TARGET']==1]\n",
    "default_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df_balanced = pd.concat( [default_df] * (balanceFactor - 1), sort=False, ignore_index=True )\n",
    "default_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_all_processed_df_balanced = pd.concat([appl_all_processed_df , default_df_balanced], sort=False, ignore_index=True)\n",
    "appl_all_processed_df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(appl_all_processed_df_balanced['TARGET'].unique(),\n",
    "(appl_all_processed_df_balanced['TARGET'].value_counts()[1], \\\n",
    "appl_all_processed_df_balanced['TARGET'].value_counts()[0], \\\n",
    "appl_all_processed_df_balanced['TARGET'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following gc if memory is running slow\n",
    "del appl_all_processed_df_balanced\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "* cleaning:\n",
    "    * num_df: normalize with z-score\n",
    "* feature engineering:\n",
    "    * make reciprocol, polynomial columns of the existing columns. 1/x, x^x.\n",
    "    * multiplying each columns, two columns at a time.\n",
    "    * asset items, income items, willingness(history + misc profile) items, loading(principle + interest) items\n",
    "    * Integration from other tables?\n",
    "\n",
    "https://ithelp.ithome.com.tw/articles/10202059\n",
    "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
    "https://www.kaggle.com/parasjindal96/how-to-normalize-dataframe-pandas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcol = df['CNT_FAM_MEMBERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numcol.describe(), \\\n",
    "numcol.isnull().sum(), \\\n",
    "numcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcol.value_counts(sort=True), numcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numcol_toYear = pd.to_numeric(\\\n",
    "#                               ((numcol.abs() / 365) \\\n",
    "#                                .round(0)) \\\n",
    "#                               ,downcast='integer')\n",
    "# numcol_toYear.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# numcol_toYear.value_counts(sort=True), numcol_toYear.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol = df['HOUR_APPR_PROCESS_START']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.unique(), \\\n",
    "catcol.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol.isnull().sum(), \\\n",
    "catcol.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool: Getting summary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might not be very useful at this point\n",
    "def summary_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    summary_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return summary_df\n",
    "\n",
    "def data_quality_df (data_df):\n",
    "    \"\"\" \n",
    "    Output: a new dataframe with summary info from the input dataframe.\n",
    "    Input: data_df, the original dataframe\n",
    "    \"\"\"\n",
    "    data_quality_df = pd.concat([(data_df.describe(include='all')), \\\n",
    "           (data_df.dtypes.to_frame(name='dtypes').T), \\\n",
    "           (data_df.isnull().sum().to_frame(name='isnull').T), \\\n",
    "           (data_df.apply(lambda x:x.unique().size).to_frame(name='uniqAll').T)])\n",
    "    return data_quality_df.iloc[[11,13,12,0,],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_quality_df(appl_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# data_quality_df(df).to_csv(\"./eda_output/application_train_data_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_CHILDREN'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(file_name, encoding='utf-8', index=False)\n",
    "# summary_df(df).to_csv(\"./eda_output/application_train_summary_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .nunique() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique() function excludes NaN \n",
    "# i.e. it does not consider NaN as a \"value\", therefore NaN is not counted as a \"unique value\"\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() == df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .value_counts() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .value_counts() function has similar viewpoint towards NaN.\n",
    "# i.e. it does not consider null as a value, therefore not counted in .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['NAME_TYPE_SUITE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].value_counts().sum() + df['AMT_REQ_CREDIT_BUREAU_YEAR'].isnull().sum() == \\\n",
    "df['AMT_REQ_CREDIT_BUREAU_YEAR'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重複值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting unique values (cf. .nunique() function, see above section)\n",
    "# This code was retrieved from HT\n",
    "\n",
    "df.apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the same if you write (df.apply(lambda x:x.unique().size))\n",
    "assert (df.apply(lambda x:x.unique().shape[0])==df.apply(lambda x:x.unique().size)).all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %timeit showed the performances are similar\n",
    "# %timeit df.apply(lambda x:x.unique().shape[0])\n",
    "# %timeit df.apply(lambda x:x.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 含空值欄位占比\n",
    "print(f\"{df.isnull().any().sum()} in {df.shape[1]} columns (ratio: {(df.isnull().any().sum()/df.shape[1]).round(2)}) has empty value(s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-casting to reduce memory use (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isfinite(num_df).all().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite = num_df[num_df.columns[np.isfinite(num_df).all()]]\n",
    "# num_df_infinite = num_df[num_df.columns[np.isfinite(num_df).all() == False]]\n",
    "# num_df_finite.shape, num_df_infinite.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert num_df_finite.shape[0] == num_df_infinite.shape[0] == num_df.shape[0]\n",
    "# assert num_df_finite.shape[1] + num_df_infinite.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_mem_usage(props, finite:bool = True):\n",
    "#     props.info(verbose=False)\n",
    "#     start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "#     print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "#     if finite == True:  \n",
    "#         props[props.columns[(props.min()>=0) & (props.max()<255)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) & (props.max()<255)]].astype(np.uint8, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 255) & (props.max()<65535)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 255) & (props.max()<65535)]] \\\n",
    "#         .astype(np.uint16, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 65535) & (props.max()<4294967295)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 65535) & (props.max()<4294967295)]] \\\n",
    "#         .astype(np.uint32, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 4294967295)]] = \\\n",
    "#         props[props.columns[(props.min()>=0) &(props.max() >= 4294967295)]] \\\n",
    "#         .astype(np.uint64, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "#     else:\n",
    "#         props = props.astype(np.float32, copy=False)\n",
    "#         props.info(verbose=False)\n",
    "        \n",
    "#     print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "#     mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "#     print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "#     print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    \n",
    "#     return props\n",
    "\n",
    "# if num_na_df_finite.min()>=0:\n",
    "#     if num_na_df_finite.max() < 255:\n",
    "#         props[col] = props[col].astype(np.uint8)\n",
    "#     elif num_na_df_finite.max() < 65535:\n",
    "#         props[col] = props[col].astype(np.uint16)\n",
    "#     elif num_na_df_finite.max() < 4294967295:\n",
    "#         props[col] = props[col].astype(np.uint32)\n",
    "#     else:\n",
    "#         props[col] = props[col].astype(np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_finite = reduce_mem_usage(num_df_finite, finite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_infinite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df_infinite = reduce_mem_usage(num_df_infinite, finite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_df = pd.concat([num_df_finite, num_df_infinite], axis ='columns')\n",
    "# num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert num_df_finite.shape[0] == num_df_infinite.shape[0] == num_df.shape[0]\n",
    "# assert num_df_finite.shape[1] + num_df_infinite.shape[1] == num_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del num_df_finite\n",
    "# del num_df_infinite\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
