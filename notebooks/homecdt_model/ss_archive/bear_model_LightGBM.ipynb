{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#取消科學記號\n",
    "pd.options.display.float_format = '{:.7f}'.format  #pandas 取消科學記號，只顯示小數點第二位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv('C:/Shared/machine_learning/home-credit-default-risk/application_train.csv')\n",
    "app_test = pd.read_csv('C:/Shared/machine_learning/home-credit-default-risk/application_test.csv')\n",
    "final_train = pd.read_csv('C:/Shared/machine_learning/home-credit-default-risk/final_train.csv')\n",
    "final_test = pd.read_csv('C:/Shared/machine_learning/home-credit-default-risk/final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "def model(features, test_features, encoding = 'ohe', n_folds = 5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #ID 取出\n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    #目標取出\n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    #刪除train 的目標和ID ，刪除test的ID\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    #分兩種方法'ohe':將train和test都做one hot建立虛擬變數(攤平)，並且根據兩者都有得col項目合併\n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        #enumerate() 將資料變成((0,apptrain.columns[0]), (1,apptrain_columns[1])....)一對一放進 i 和 col跑迴圈\n",
    "        #LabelEncoder.fit_transform 將 object變數做重新編碼從 0 開始\n",
    "        #試試這行 : label_encoder.fit_transform(['a','a','b','c','a','b'])\n",
    "        #cat_indices 為object的索引\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    #encoding參數給錯就報錯\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    #取出特徵名稱\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    #dataframe 轉成np.array\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    #建立長度和特徵名稱一樣長且全為 0 的 np.array\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    #建立長度和測試資料筆數一樣長且全為 0 的 np.array\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    #建立長度和訓練資料筆數一樣長且全為 0 的 np.array\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    #記錄驗證和訓練的成績\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    # 迭代所有交叉驗證集\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        #交叉訓練資料\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        \n",
    "        # Validation data for the fold\n",
    "        #交叉驗證資料\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        #建立 LGBM模型參數\n",
    "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        #訓練開始\n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307507, 869)\n",
      "Testing Data Shape:  (48744, 869)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's binary_logloss: 0.529605\tvalid's auc: 0.781281\ttrain's binary_logloss: 0.515641\ttrain's auc: 0.834975\n",
      "[400]\tvalid's binary_logloss: 0.502599\tvalid's auc: 0.782659\ttrain's binary_logloss: 0.47567\ttrain's auc: 0.872659\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid's binary_logloss: 0.505889\tvalid's auc: 0.782824\ttrain's binary_logloss: 0.480648\ttrain's auc: 0.868228\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's binary_logloss: 0.529414\tvalid's auc: 0.789708\ttrain's binary_logloss: 0.517895\ttrain's auc: 0.832897\n",
      "[400]\tvalid's binary_logloss: 0.501943\tvalid's auc: 0.791013\ttrain's binary_logloss: 0.477773\ttrain's auc: 0.871454\n",
      "Early stopping, best iteration is:\n",
      "[397]\tvalid's binary_logloss: 0.502322\tvalid's auc: 0.791045\ttrain's binary_logloss: 0.478337\ttrain's auc: 0.870917\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's binary_logloss: 0.529395\tvalid's auc: 0.787777\ttrain's binary_logloss: 0.517182\ttrain's auc: 0.833825\n",
      "[400]\tvalid's binary_logloss: 0.502091\tvalid's auc: 0.789024\ttrain's binary_logloss: 0.477536\ttrain's auc: 0.87174\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid's binary_logloss: 0.509278\tvalid's auc: 0.789144\ttrain's binary_logloss: 0.488298\ttrain's auc: 0.862011\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's binary_logloss: 0.531648\tvalid's auc: 0.784649\ttrain's binary_logloss: 0.516572\ttrain's auc: 0.834149\n",
      "[400]\tvalid's binary_logloss: 0.50498\tvalid's auc: 0.785038\ttrain's binary_logloss: 0.477199\ttrain's auc: 0.871839\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid's binary_logloss: 0.516754\tvalid's auc: 0.785491\ttrain's binary_logloss: 0.495117\ttrain's auc: 0.855388\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's binary_logloss: 0.532727\tvalid's auc: 0.78236\ttrain's binary_logloss: 0.515161\ttrain's auc: 0.835447\n",
      "[400]\tvalid's binary_logloss: 0.506406\tvalid's auc: 0.782869\ttrain's binary_logloss: 0.475602\ttrain's auc: 0.872978\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid's binary_logloss: 0.515151\tvalid's auc: 0.783376\ttrain's binary_logloss: 0.488895\ttrain's auc: 0.860935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       SK_ID_CURR    TARGET\n",
       " 0          100001 0.3216596\n",
       " 1          100005 0.5739773\n",
       " 2          100013 0.2117655\n",
       " 3          100028 0.2800243\n",
       " 4          100038 0.6988437\n",
       " ...           ...       ...\n",
       " 48739      456221 0.3580784\n",
       " 48740      456222 0.4044381\n",
       " 48741      456223 0.0558504\n",
       " 48742      456224 0.2500496\n",
       " 48743      456250 0.7262148\n",
       " \n",
       " [48744 rows x 2 columns],                               feature  importance\n",
       " 0                          Unnamed: 0  37.2000000\n",
       " 1                               index   0.0000000\n",
       " 2                         AMT_ANNUITY 138.6000000\n",
       " 3                          AMT_CREDIT  62.6000000\n",
       " 4                     AMT_GOODS_PRICE  74.6000000\n",
       " ..                                ...         ...\n",
       " 864   CC_NAME_CONTRACT_STATUS_nan_MAX   0.0000000\n",
       " 865  CC_NAME_CONTRACT_STATUS_nan_MEAN   0.0000000\n",
       " 866   CC_NAME_CONTRACT_STATUS_nan_SUM   0.0000000\n",
       " 867   CC_NAME_CONTRACT_STATUS_nan_VAR   0.0000000\n",
       " 868                          CC_COUNT   2.4000000\n",
       " \n",
       " [869 rows x 2 columns],       fold     train     valid\n",
       " 0        0 0.8682277 0.7828243\n",
       " 1        1 0.8709170 0.7910454\n",
       " 2        2 0.8620114 0.7891436\n",
       " 3        3 0.8553884 0.7854905\n",
       " 4        4 0.8609349 0.7833761\n",
       " 5  overall 0.8634959 0.7863419)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(final_train,final_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
