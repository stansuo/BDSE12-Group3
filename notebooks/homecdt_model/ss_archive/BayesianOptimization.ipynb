{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/homeCredit/BDSE12_03G_HomeCredit_V2.csv')\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = LGBMClassifier(**params, \n",
    "                         n_estimators = 2000,\n",
    "                         nthread = 5, \n",
    "                         boosting_type='goss', \n",
    "                         objective='binary')\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = XGBClassifier(**params, \n",
    "                        n_estimators = 2000, \n",
    "                        nthread = 5, \n",
    "                        objective= 'binary:logistic')\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | reg_alpha | reg_la... | scale_... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.01, .03), \n",
    "          'subsample': (.0, 1.0), \n",
    "          'max_depth': (4, 9), \n",
    "          'reg_alpha': (.0, 1.0), \n",
    "          'reg_lambda': (.0, 1.0), \n",
    "          'scale_pos_weight': (.0, 5.0),\n",
    "          'colsample_bytree': (.0, 1.0)}\n",
    "bo = BayesianOptimization(xgb_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7935  \u001b[0m | \u001b[0m 0.01112 \u001b[0m | \u001b[0m 7.106   \u001b[0m | \u001b[0m 44.6    \u001b[0m | \u001b[0m 0.01451 \u001b[0m | \u001b[0m 91.72   \u001b[0m | \u001b[0m 0.09609 \u001b[0m | \u001b[0m 0.3668  \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 0.02896 \u001b[0m | \u001b[0m 6.387   \u001b[0m | \u001b[0m 57.54   \u001b[0m | \u001b[0m 0.02782 \u001b[0m | \u001b[0m 23.84   \u001b[0m | \u001b[0m 0.05095 \u001b[0m | \u001b[0m 0.6451  \u001b[0m | \u001b[0m 0.8986  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.793   \u001b[0m | \u001b[0m 0.02692 \u001b[0m | \u001b[0m 7.423   \u001b[0m | \u001b[0m 62.36   \u001b[0m | \u001b[0m 0.02013 \u001b[0m | \u001b[0m 92.88   \u001b[0m | \u001b[0m 0.6868  \u001b[0m | \u001b[0m 0.8196  \u001b[0m | \u001b[0m 0.9318  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7934  \u001b[0m | \u001b[0m 0.01211 \u001b[0m | \u001b[0m 6.622   \u001b[0m | \u001b[0m 68.66   \u001b[0m | \u001b[0m 0.01294 \u001b[0m | \u001b[0m 54.74   \u001b[0m | \u001b[0m 0.108   \u001b[0m | \u001b[0m 0.3523  \u001b[0m | \u001b[0m 0.8212  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7938  \u001b[0m | \u001b[95m 0.01929 \u001b[0m | \u001b[95m 8.672   \u001b[0m | \u001b[95m 67.28   \u001b[0m | \u001b[95m 0.0162  \u001b[0m | \u001b[95m 33.82   \u001b[0m | \u001b[95m 0.5987  \u001b[0m | \u001b[95m 0.6734  \u001b[0m | \u001b[95m 0.9283  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.01324 \u001b[0m | \u001b[0m 8.177   \u001b[0m | \u001b[0m 20.21   \u001b[0m | \u001b[0m 0.01961 \u001b[0m | \u001b[0m 20.01   \u001b[0m | \u001b[0m 0.4762  \u001b[0m | \u001b[0m 0.7955  \u001b[0m | \u001b[0m 0.8782  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7917  \u001b[0m | \u001b[0m 0.0244  \u001b[0m | \u001b[0m 8.553   \u001b[0m | \u001b[0m 20.09   \u001b[0m | \u001b[0m 0.02207 \u001b[0m | \u001b[0m 99.99   \u001b[0m | \u001b[0m 0.09345 \u001b[0m | \u001b[0m 0.3161  \u001b[0m | \u001b[0m 0.9177  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01014 \u001b[0m | \u001b[0m 8.019   \u001b[0m | \u001b[0m 69.7    \u001b[0m | \u001b[0m 0.01676 \u001b[0m | \u001b[0m 20.13   \u001b[0m | \u001b[0m 0.7067  \u001b[0m | \u001b[0m 0.5098  \u001b[0m | \u001b[0m 0.8312  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.01348 \u001b[0m | \u001b[0m 8.441   \u001b[0m | \u001b[0m 69.92   \u001b[0m | \u001b[0m 0.02964 \u001b[0m | \u001b[0m 20.14   \u001b[0m | \u001b[0m 0.0248  \u001b[0m | \u001b[0m 0.5447  \u001b[0m | \u001b[0m 0.9762  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.02806 \u001b[0m | \u001b[0m 7.679   \u001b[0m | \u001b[0m 69.87   \u001b[0m | \u001b[0m 0.02871 \u001b[0m | \u001b[0m 99.71   \u001b[0m | \u001b[0m 0.8277  \u001b[0m | \u001b[0m 0.741   \u001b[0m | \u001b[0m 0.8438  \u001b[0m |\n",
      "=========================================================================================================================\n",
      "Elapsed time=9084.18 sec.\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.01, .03), \n",
    "          'num_leaves': (20, 100), \n",
    "          'subsample': (0.8, 1), \n",
    "          'max_depth': (6, 9), \n",
    "          'reg_alpha': (.00, 1.0), \n",
    "          'reg_lambda': (.00, 1.0), \n",
    "          'min_split_gain': (.01, .03),\n",
    "          'min_child_weight': (20, 70)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.792940652843537,\n",
       " 'params': {'learning_rate': 0.013237147439636492,\n",
       "  'max_depth': 8.176972909272658,\n",
       "  'min_child_weight': 20.210808853599698,\n",
       "  'min_split_gain': 0.019613448600170856,\n",
       "  'num_leaves': 20.01281707147962,\n",
       "  'reg_alpha': 0.4762374177443556,\n",
       "  'reg_lambda': 0.795459509951648,\n",
       "  'subsample': 0.8782478787186309}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.res[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.789   \u001b[0m | \u001b[0m 0.06537 \u001b[0m | \u001b[0m 8.788   \u001b[0m | \u001b[0m 22.77   \u001b[0m | \u001b[0m 0.08022 \u001b[0m | \u001b[0m 60.89   \u001b[0m | \u001b[0m 0.9679  \u001b[0m | \u001b[0m 0.2213  \u001b[0m | \u001b[0m 0.4622  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7921  \u001b[0m | \u001b[95m 0.0361  \u001b[0m | \u001b[95m 8.687   \u001b[0m | \u001b[95m 41.12   \u001b[0m | \u001b[95m 0.08093 \u001b[0m | \u001b[95m 61.53   \u001b[0m | \u001b[95m 0.8299  \u001b[0m | \u001b[95m 0.4435  \u001b[0m | \u001b[95m 0.6061  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7937  \u001b[0m | \u001b[95m 0.0138  \u001b[0m | \u001b[95m 8.885   \u001b[0m | \u001b[95m 57.73   \u001b[0m | \u001b[95m 0.07277 \u001b[0m | \u001b[95m 81.73   \u001b[0m | \u001b[95m 0.6619  \u001b[0m | \u001b[95m 0.3204  \u001b[0m | \u001b[95m 0.5381  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7909  \u001b[0m | \u001b[0m 0.07356 \u001b[0m | \u001b[0m 7.91    \u001b[0m | \u001b[0m 63.69   \u001b[0m | \u001b[0m 0.04934 \u001b[0m | \u001b[0m 44.67   \u001b[0m | \u001b[0m 0.05158 \u001b[0m | \u001b[0m 0.6932  \u001b[0m | \u001b[0m 0.08962 \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7905  \u001b[0m | \u001b[0m 0.07356 \u001b[0m | \u001b[0m 6.978   \u001b[0m | \u001b[0m 62.94   \u001b[0m | \u001b[0m 0.08465 \u001b[0m | \u001b[0m 58.14   \u001b[0m | \u001b[0m 0.5698  \u001b[0m | \u001b[0m 0.2101  \u001b[0m | \u001b[0m 0.3065  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7911  \u001b[0m | \u001b[0m 0.04674 \u001b[0m | \u001b[0m 8.316   \u001b[0m | \u001b[0m 69.69   \u001b[0m | \u001b[0m 0.06259 \u001b[0m | \u001b[0m 99.95   \u001b[0m | \u001b[0m 0.1455  \u001b[0m | \u001b[0m 0.6733  \u001b[0m | \u001b[0m 0.2921  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.792   \u001b[0m | \u001b[0m 0.04338 \u001b[0m | \u001b[0m 7.319   \u001b[0m | \u001b[0m 69.84   \u001b[0m | \u001b[0m 0.06505 \u001b[0m | \u001b[0m 99.97   \u001b[0m | \u001b[0m 0.7313  \u001b[0m | \u001b[0m 0.7722  \u001b[0m | \u001b[0m 0.7551  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7903  \u001b[0m | \u001b[0m 0.05267 \u001b[0m | \u001b[0m 6.578   \u001b[0m | \u001b[0m 20.03   \u001b[0m | \u001b[0m 0.008626\u001b[0m | \u001b[0m 99.9    \u001b[0m | \u001b[0m 0.5929  \u001b[0m | \u001b[0m 0.023   \u001b[0m | \u001b[0m 0.4019  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.792   \u001b[0m | \u001b[0m 0.05295 \u001b[0m | \u001b[0m 7.934   \u001b[0m | \u001b[0m 69.89   \u001b[0m | \u001b[0m 0.06285 \u001b[0m | \u001b[0m 20.41   \u001b[0m | \u001b[0m 0.4346  \u001b[0m | \u001b[0m 0.7324  \u001b[0m | \u001b[0m 0.7179  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7931  \u001b[0m | \u001b[0m 0.02716 \u001b[0m | \u001b[0m 8.816   \u001b[0m | \u001b[0m 69.79   \u001b[0m | \u001b[0m 0.007781\u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.133   \u001b[0m | \u001b[0m 0.3739  \u001b[0m | \u001b[0m 0.887   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7864  \u001b[0m | \u001b[0m 0.004281\u001b[0m | \u001b[0m 8.454   \u001b[0m | \u001b[0m 69.99   \u001b[0m | \u001b[0m 0.03759 \u001b[0m | \u001b[0m 20.08   \u001b[0m | \u001b[0m 0.2012  \u001b[0m | \u001b[0m 0.8279  \u001b[0m | \u001b[0m 0.9796  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7924  \u001b[0m | \u001b[0m 0.03478 \u001b[0m | \u001b[0m 7.031   \u001b[0m | \u001b[0m 69.89   \u001b[0m | \u001b[0m 0.0997  \u001b[0m | \u001b[0m 99.48   \u001b[0m | \u001b[0m 0.2128  \u001b[0m | \u001b[0m 0.9046  \u001b[0m | \u001b[0m 0.342   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7922  \u001b[0m | \u001b[0m 0.04115 \u001b[0m | \u001b[0m 7.625   \u001b[0m | \u001b[0m 69.75   \u001b[0m | \u001b[0m 0.0697  \u001b[0m | \u001b[0m 99.83   \u001b[0m | \u001b[0m 0.4203  \u001b[0m | \u001b[0m 0.1743  \u001b[0m | \u001b[0m 0.08217 \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.08329 \u001b[0m | \u001b[0m 8.704   \u001b[0m | \u001b[0m 69.83   \u001b[0m | \u001b[0m 0.07767 \u001b[0m | \u001b[0m 99.78   \u001b[0m | \u001b[0m 0.1427  \u001b[0m | \u001b[0m 0.9089  \u001b[0m | \u001b[0m 0.9083  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.09846 \u001b[0m | \u001b[0m 7.836   \u001b[0m | \u001b[0m 69.96   \u001b[0m | \u001b[0m 0.07031 \u001b[0m | \u001b[0m 99.95   \u001b[0m | \u001b[0m 0.9447  \u001b[0m | \u001b[0m 0.4432  \u001b[0m | \u001b[0m 0.9246  \u001b[0m |\n",
      "=========================================================================================================================\n",
      "Elapsed time=7734.96 sec.\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.0, .1), \n",
    "          'num_leaves': (20, 100), \n",
    "          'subsample': (.0, 1.0), \n",
    "          'max_depth': (6, 9), \n",
    "          'reg_alpha': (.00, 1.0), \n",
    "          'reg_lambda': (.00, 1.0), \n",
    "          'min_split_gain': (.0, .1),\n",
    "          'min_child_weight': (20, 70)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 10)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7936603978356124,\n",
       " 'params': {'learning_rate': 0.013803211212539657,\n",
       "  'max_depth': 8.884921565475697,\n",
       "  'min_child_weight': 57.725650927715265,\n",
       "  'min_split_gain': 0.07276947619457204,\n",
       "  'num_leaves': 81.72909839300354,\n",
       "  'reg_alpha': 0.6618734111073816,\n",
       "  'reg_lambda': 0.320433363007782,\n",
       "  'subsample': 0.5381263969882377}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.res[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
