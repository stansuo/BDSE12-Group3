{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/homeCredit/BDSE12_03G_HomeCredit_V2.csv')\n",
    "df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "\n",
    "def process_dataframe(input_df, encoder_dict=None):\n",
    "    \"\"\" Process a dataframe into a form useable by LightGBM \"\"\"\n",
    "\n",
    "    # Label encode categoricals\n",
    "    categorical_feats = input_df.columns[input_df.dtypes == 'object']\n",
    "    categorical_feats = categorical_feats\n",
    "    encoder_dict = {}\n",
    "    for feat in categorical_feats:\n",
    "        encoder = LabelEncoder()\n",
    "        input_df[feat] = encoder.fit_transform(input_df[feat].fillna('NULL'))\n",
    "        encoder_dict[feat] = encoder\n",
    "\n",
    "    return input_df, categorical_feats.tolist(), encoder_dict\n",
    "\n",
    "df, categorical_feats, encoder_dict = process_dataframe(input_df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = LGBMClassifier(**params, \n",
    "                         n_estimators = 2000,\n",
    "                         nthread = 5, \n",
    "                         boosting_type='rf', \n",
    "                         objective='binary')\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = XGBClassifier(**params, \n",
    "                        n_estimators = 2000, \n",
    "                        nthread = 5, \n",
    "                        objective= 'binary:logistic')\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.01, .03), \n",
    "          'subsample': (.0, 1.0), \n",
    "          'max_depth': (4, 9), \n",
    "          'reg_alpha': (.0, 1.0), \n",
    "          'reg_lambda': (.0, 1.0), \n",
    "          'scale_pos_weight': (.0, 5.0),\n",
    "          'colsample_bytree': (.0, 1.0)}\n",
    "bo = BayesianOptimization(xgb_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 29 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.020365528198042368, 7.011519084805997, 21.3497526096477, 0.027399076490833944, 72.42684869233689, 0.9322894056157585, 0.25476347994720716, 0.8259658528692875)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d3c5f4ec431f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m           'min_child_weight': (20, 70)}\n\u001b[0;32m     10\u001b[0m \u001b[0mbo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_evaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Elapsed time={:5.2f} sec.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0minit_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-0802715121d6>\u001b[0m in \u001b[0;36mlgbm_evaluate\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     26\u001b[0m         clf.fit(train_x, train_y, \n\u001b[0;32m     27\u001b[0m                 \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 verbose = False, early_stopping_rounds = 100)\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtest_pred_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    724\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 726\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    727\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    497\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[0;32m   1453\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m                 ctypes.byref(self.handle)))\n\u001b[0m\u001b[0;32m   1456\u001b[0m             \u001b[1;31m# save reference to data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \"\"\"\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at d:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 29 .\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.01, .03), \n",
    "          'num_leaves': (20, 100), \n",
    "          'subsample': (0.8, 1), \n",
    "          'max_depth': (6, 9), \n",
    "          'reg_alpha': (.00, 1.0), \n",
    "          'reg_lambda': (.00, 1.0), \n",
    "          'min_split_gain': (.01, .03),\n",
    "          'min_child_weight': (20, 70),\n",
    "          'subsample_freq':(0, 10)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7935  \u001b[0m | \u001b[0m 0.01112 \u001b[0m | \u001b[0m 7.106   \u001b[0m | \u001b[0m 44.6    \u001b[0m | \u001b[0m 0.01451 \u001b[0m | \u001b[0m 91.72   \u001b[0m | \u001b[0m 0.09609 \u001b[0m | \u001b[0m 0.3668  \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 0.02896 \u001b[0m | \u001b[0m 6.387   \u001b[0m | \u001b[0m 57.54   \u001b[0m | \u001b[0m 0.02782 \u001b[0m | \u001b[0m 23.84   \u001b[0m | \u001b[0m 0.05095 \u001b[0m | \u001b[0m 0.6451  \u001b[0m | \u001b[0m 0.8986  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.793   \u001b[0m | \u001b[0m 0.02692 \u001b[0m | \u001b[0m 7.423   \u001b[0m | \u001b[0m 62.36   \u001b[0m | \u001b[0m 0.02013 \u001b[0m | \u001b[0m 92.88   \u001b[0m | \u001b[0m 0.6868  \u001b[0m | \u001b[0m 0.8196  \u001b[0m | \u001b[0m 0.9318  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7934  \u001b[0m | \u001b[0m 0.01211 \u001b[0m | \u001b[0m 6.622   \u001b[0m | \u001b[0m 68.66   \u001b[0m | \u001b[0m 0.01294 \u001b[0m | \u001b[0m 54.74   \u001b[0m | \u001b[0m 0.108   \u001b[0m | \u001b[0m 0.3523  \u001b[0m | \u001b[0m 0.8212  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7938  \u001b[0m | \u001b[95m 0.01929 \u001b[0m | \u001b[95m 8.672   \u001b[0m | \u001b[95m 67.28   \u001b[0m | \u001b[95m 0.0162  \u001b[0m | \u001b[95m 33.82   \u001b[0m | \u001b[95m 0.5987  \u001b[0m | \u001b[95m 0.6734  \u001b[0m | \u001b[95m 0.9283  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.01324 \u001b[0m | \u001b[0m 8.177   \u001b[0m | \u001b[0m 20.21   \u001b[0m | \u001b[0m 0.01961 \u001b[0m | \u001b[0m 20.01   \u001b[0m | \u001b[0m 0.4762  \u001b[0m | \u001b[0m 0.7955  \u001b[0m | \u001b[0m 0.8782  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7917  \u001b[0m | \u001b[0m 0.0244  \u001b[0m | \u001b[0m 8.553   \u001b[0m | \u001b[0m 20.09   \u001b[0m | \u001b[0m 0.02207 \u001b[0m | \u001b[0m 99.99   \u001b[0m | \u001b[0m 0.09345 \u001b[0m | \u001b[0m 0.3161  \u001b[0m | \u001b[0m 0.9177  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.01014 \u001b[0m | \u001b[0m 8.019   \u001b[0m | \u001b[0m 69.7    \u001b[0m | \u001b[0m 0.01676 \u001b[0m | \u001b[0m 20.13   \u001b[0m | \u001b[0m 0.7067  \u001b[0m | \u001b[0m 0.5098  \u001b[0m | \u001b[0m 0.8312  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 0.01348 \u001b[0m | \u001b[0m 8.441   \u001b[0m | \u001b[0m 69.92   \u001b[0m | \u001b[0m 0.02964 \u001b[0m | \u001b[0m 20.14   \u001b[0m | \u001b[0m 0.0248  \u001b[0m | \u001b[0m 0.5447  \u001b[0m | \u001b[0m 0.9762  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.02806 \u001b[0m | \u001b[0m 7.679   \u001b[0m | \u001b[0m 69.87   \u001b[0m | \u001b[0m 0.02871 \u001b[0m | \u001b[0m 99.71   \u001b[0m | \u001b[0m 0.8277  \u001b[0m | \u001b[0m 0.741   \u001b[0m | \u001b[0m 0.8438  \u001b[0m |\n",
      "=========================================================================================================================\n",
      "Elapsed time=9084.18 sec.\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.01, .03), \n",
    "          'num_leaves': (20, 100), \n",
    "          'subsample': (0.8, 1), \n",
    "          'max_depth': (6, 9), \n",
    "          'reg_alpha': (.00, 1.0), \n",
    "          'reg_lambda': (.00, 1.0), \n",
    "          'min_split_gain': (.01, .03),\n",
    "          'min_child_weight': (20, 70)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.792940652843537,\n",
       " 'params': {'learning_rate': 0.013237147439636492,\n",
       "  'max_depth': 8.176972909272658,\n",
       "  'min_child_weight': 20.210808853599698,\n",
       "  'min_split_gain': 0.019613448600170856,\n",
       "  'num_leaves': 20.01281707147962,\n",
       "  'reg_alpha': 0.4762374177443556,\n",
       "  'reg_lambda': 0.795459509951648,\n",
       "  'subsample': 0.8782478787186309}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.res[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.789   \u001b[0m | \u001b[0m 0.06537 \u001b[0m | \u001b[0m 8.788   \u001b[0m | \u001b[0m 22.77   \u001b[0m | \u001b[0m 0.08022 \u001b[0m | \u001b[0m 60.89   \u001b[0m | \u001b[0m 0.9679  \u001b[0m | \u001b[0m 0.2213  \u001b[0m | \u001b[0m 0.4622  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7921  \u001b[0m | \u001b[95m 0.0361  \u001b[0m | \u001b[95m 8.687   \u001b[0m | \u001b[95m 41.12   \u001b[0m | \u001b[95m 0.08093 \u001b[0m | \u001b[95m 61.53   \u001b[0m | \u001b[95m 0.8299  \u001b[0m | \u001b[95m 0.4435  \u001b[0m | \u001b[95m 0.6061  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7937  \u001b[0m | \u001b[95m 0.0138  \u001b[0m | \u001b[95m 8.885   \u001b[0m | \u001b[95m 57.73   \u001b[0m | \u001b[95m 0.07277 \u001b[0m | \u001b[95m 81.73   \u001b[0m | \u001b[95m 0.6619  \u001b[0m | \u001b[95m 0.3204  \u001b[0m | \u001b[95m 0.5381  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7909  \u001b[0m | \u001b[0m 0.07356 \u001b[0m | \u001b[0m 7.91    \u001b[0m | \u001b[0m 63.69   \u001b[0m | \u001b[0m 0.04934 \u001b[0m | \u001b[0m 44.67   \u001b[0m | \u001b[0m 0.05158 \u001b[0m | \u001b[0m 0.6932  \u001b[0m | \u001b[0m 0.08962 \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7905  \u001b[0m | \u001b[0m 0.07356 \u001b[0m | \u001b[0m 6.978   \u001b[0m | \u001b[0m 62.94   \u001b[0m | \u001b[0m 0.08465 \u001b[0m | \u001b[0m 58.14   \u001b[0m | \u001b[0m 0.5698  \u001b[0m | \u001b[0m 0.2101  \u001b[0m | \u001b[0m 0.3065  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7911  \u001b[0m | \u001b[0m 0.04674 \u001b[0m | \u001b[0m 8.316   \u001b[0m | \u001b[0m 69.69   \u001b[0m | \u001b[0m 0.06259 \u001b[0m | \u001b[0m 99.95   \u001b[0m | \u001b[0m 0.1455  \u001b[0m | \u001b[0m 0.6733  \u001b[0m | \u001b[0m 0.2921  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.792   \u001b[0m | \u001b[0m 0.04338 \u001b[0m | \u001b[0m 7.319   \u001b[0m | \u001b[0m 69.84   \u001b[0m | \u001b[0m 0.06505 \u001b[0m | \u001b[0m 99.97   \u001b[0m | \u001b[0m 0.7313  \u001b[0m | \u001b[0m 0.7722  \u001b[0m | \u001b[0m 0.7551  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7903  \u001b[0m | \u001b[0m 0.05267 \u001b[0m | \u001b[0m 6.578   \u001b[0m | \u001b[0m 20.03   \u001b[0m | \u001b[0m 0.008626\u001b[0m | \u001b[0m 99.9    \u001b[0m | \u001b[0m 0.5929  \u001b[0m | \u001b[0m 0.023   \u001b[0m | \u001b[0m 0.4019  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.792   \u001b[0m | \u001b[0m 0.05295 \u001b[0m | \u001b[0m 7.934   \u001b[0m | \u001b[0m 69.89   \u001b[0m | \u001b[0m 0.06285 \u001b[0m | \u001b[0m 20.41   \u001b[0m | \u001b[0m 0.4346  \u001b[0m | \u001b[0m 0.7324  \u001b[0m | \u001b[0m 0.7179  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7931  \u001b[0m | \u001b[0m 0.02716 \u001b[0m | \u001b[0m 8.816   \u001b[0m | \u001b[0m 69.79   \u001b[0m | \u001b[0m 0.007781\u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.133   \u001b[0m | \u001b[0m 0.3739  \u001b[0m | \u001b[0m 0.887   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7864  \u001b[0m | \u001b[0m 0.004281\u001b[0m | \u001b[0m 8.454   \u001b[0m | \u001b[0m 69.99   \u001b[0m | \u001b[0m 0.03759 \u001b[0m | \u001b[0m 20.08   \u001b[0m | \u001b[0m 0.2012  \u001b[0m | \u001b[0m 0.8279  \u001b[0m | \u001b[0m 0.9796  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7924  \u001b[0m | \u001b[0m 0.03478 \u001b[0m | \u001b[0m 7.031   \u001b[0m | \u001b[0m 69.89   \u001b[0m | \u001b[0m 0.0997  \u001b[0m | \u001b[0m 99.48   \u001b[0m | \u001b[0m 0.2128  \u001b[0m | \u001b[0m 0.9046  \u001b[0m | \u001b[0m 0.342   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7922  \u001b[0m | \u001b[0m 0.04115 \u001b[0m | \u001b[0m 7.625   \u001b[0m | \u001b[0m 69.75   \u001b[0m | \u001b[0m 0.0697  \u001b[0m | \u001b[0m 99.83   \u001b[0m | \u001b[0m 0.4203  \u001b[0m | \u001b[0m 0.1743  \u001b[0m | \u001b[0m 0.08217 \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.08329 \u001b[0m | \u001b[0m 8.704   \u001b[0m | \u001b[0m 69.83   \u001b[0m | \u001b[0m 0.07767 \u001b[0m | \u001b[0m 99.78   \u001b[0m | \u001b[0m 0.1427  \u001b[0m | \u001b[0m 0.9089  \u001b[0m | \u001b[0m 0.9083  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7884  \u001b[0m | \u001b[0m 0.09846 \u001b[0m | \u001b[0m 7.836   \u001b[0m | \u001b[0m 69.96   \u001b[0m | \u001b[0m 0.07031 \u001b[0m | \u001b[0m 99.95   \u001b[0m | \u001b[0m 0.9447  \u001b[0m | \u001b[0m 0.4432  \u001b[0m | \u001b[0m 0.9246  \u001b[0m |\n",
      "=========================================================================================================================\n",
      "Elapsed time=7734.96 sec.\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "params = {'learning_rate': (.0, .1), \n",
    "          'num_leaves': (20, 100), \n",
    "          'subsample': (.0, 1.0), \n",
    "          'max_depth': (6, 9), \n",
    "          'reg_alpha': (.00, 1.0), \n",
    "          'reg_lambda': (.00, 1.0), \n",
    "          'min_split_gain': (.0, .1),\n",
    "          'min_child_weight': (20, 70)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 5, n_iter = 10)\n",
    "print(\"Elapsed time={:5.2f} sec.\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7936603978356124,\n",
       " 'params': {'learning_rate': 0.013803211212539657,\n",
       "  'max_depth': 8.884921565475697,\n",
       "  'min_child_weight': 57.725650927715265,\n",
       "  'min_split_gain': 0.07276947619457204,\n",
       "  'num_leaves': 81.72909839300354,\n",
       "  'reg_alpha': 0.6618734111073816,\n",
       "  'reg_lambda': 0.320433363007782,\n",
       "  'subsample': 0.5381263969882377}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo.res[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
